{"label": "There has also been significant work on #OTHEREFR; #REFR, such that even 3More details about the chunk parser can be found in #OTHEREFR. input urerance speech recognizer hypothesis L I POS tagger , prepro e. ,ngp p II II; chun par er II chunk sequence li II frame representation ", "predict": "1 http://www.cogsci.princeton.edu/wn/ 2 http://www.lsi.upc.es/ ~nlp/switchboard.html 3 http://www.cis.upenn.edu/ ciotti/chunking.html "}
{"label": "More recently, another encoder?decoder model using an RNN was proposed in #REFR, where the decoder is conditioned on a representation of either a source sentence or a source context.", "predict": "The use of neural networks for statistical machine translation was also investigated in #OTHEREFR; #REFR."}
{"label": "The idea is similar to Finkler and Neumann #OTHEREFR, though simplified for our purposes; #REFR in his VEX system also uses the method of giving sunple questions to the user (supposedly non-linguist) to learn about word is behaviour, but it is for English and primarily intended for assigning syntax properties rather than morphological.", "predict": "A more sophisticated approach to word acquisition has been described in #REFR."}
{"label": "In this section, we test our joint model on PKU and MSRA datesets provided by the Second Segmentation Bake-off #OTHEREFR #REFR.", "predict": "We evaluate our joint model on two datasets provided by the second SIGHAN bakeoff #REFR, i.e., PKU and MSRA datasets."}
{"label": "In the context of machine translation, the performance of system generally decreases with increase in the length of the sentence #REFR.", "predict": "#REFR has also mentioned that complex sentences are those that have more than one clause."}
{"label": "We perform experiments in two benchmark semantic parsing datasets: GeoQuery #OTHEREFR and ATIS #REFR.", "predict": "We evaluate our approach on two benchmark domains: ATIS #REFR and GeoQuery #OTHEREFR."}
{"label": "We used The Japanese parser KNP #OTHEREFR and The English nl-parser #REFR.", "predict": "We used the Charniak parser #REFR for English."}
{"label": "Different work exploits distributional information in different forms, including context clustering models #OTHEREFR; #REFR and Bayesian Formally, the position feature is the context words with its relative position to the target word. models.", "predict": "Different models are proposed to learn the sense representations from context distributions such as vector space model #OTHEREFR, graph-based model #REFR, and generative model #OTHEREFR."}
{"label": "There exists some work to remove noise from SMS #OTHEREFR #REFR.", "predict": "In fact there are several techniques that attempt to do just that #OTHEREFR; #REFR."}
{"label": "Research in summarization #OTHEREFR; #REFR has shown that, in genres with stereotypical structure, important sentences are often located at the beginning or end of paragraphs/documents.", "predict": "The position-based metric #REFR captures the intuition that the most salient textual units in a text are those that are located at the beginning or end of a text."}
{"label": "#REFR used monolingual recursive autoencoders for sentiment prediction, with or without parse tree information; this was perhaps the first use of a RAAM style approach on a large scale NLP task, albeit monolingual.", "predict": "The RAAM architecture has also been used for sentiment analysis #REFR."}
{"label": "The SMR technique works with statistical word classes #REFR instead of words themselves (particularly, we have used 200 classes in all experiments). ", "predict": "The system is based on the approach of #REFR, where a translation model is learned from a bilingual corpus by maximizing the translation probabilities of the original source language (S) to the target language (T), given the source language (S?) (see Figure 1). "}
{"label": "Other metrics were also calculated (e.g. the V-Measure #REFR, and Average Entropy #OTHEREFR), but these results were excluded due to space constraints and the fact that their plots are similar to those shown.", "predict": "These metrics have been shown to be robust to the choice of clustering algorithm #REFR."}
{"label": "We compare our model against a state-of-the-art statistical machine translation #OTHEREFR and an averaged perceptron edit model (PTEM) with identical features #REFR.", "predict": "For comparison, we also train and test two other transliteration models: a statistical machine translation model (SMT) #REFR and a Perceptron-based transliteration model (PTM) #OTHEREFR."}
{"label": "As shown in [#REFR], a referring expression must communicate enough information to be able to uniquely identify the intended referent in the current discourse context, but avoiding the presence of redundant or otherwise unnecessary modifiers.", "predict": "For instance, #REFR and [Lavoie and Strube, 1998] propose algorithms based on world knowledge."}
{"label": "We evaluate our proposed model with the most commonly used metrics for coreference resolution: for the OntoNotes data sets MUC #OTHEREFR, CEAF #REFR and their average F1 as used in the CoNLL 2011 and 2012 shared tasks; for the ACE data sets MUC and B .", "predict": "We evaluate the performance of our method using the widely used MUC #OTHEREFR and CEAF #REFR metrics."}
{"label": "Researchers at New Mexico State University have built an automatic algorithm \\[#REFR\\] for locating and disambiguating enus terms (head nouns) in sense definitions.", "predict": "We follow the algorithm of #REFR."}
{"label": "Such methods can achieve better performance, reaching a tagging accuracy of up to 85% on unknown words for English \\[#REFR; Weischedel et al, 1993\\].", "predict": "These methods are described in \\[#REFR\\]."}
{"label": "Experiments on two Chinese treebanks showed that our approach outperformed the baseline system #REFR by 1.31%.", "predict": "In the future, we plan to extend this work to constituency treebanks #REFR."}
{"label": "Most existing works on sentiment summarization focus on predicting the overall rating on an entity #OTHEREFR; #REFR).", "predict": "Previous research has addressed the problem of opinion summarization #OTHEREFR; #REFR."}
{"label": "#REFR propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types.", "predict": "#REFR learn a generative model to classify relations, using the parse trees of sentences to help disambiguate relations."}
{"label": "Some success in this area has been demonstrated via generative models #OTHEREFR, which often benefit from wellchosen priors #REFR or posterior constraints #OTHEREFR.", "predict": "Many recent methods have focused on learning dependency grammars #OTHEREFR; #REFR."}
{"label": "Much attention has recently been devoted to integer linear programming #OTHEREFR; #REFR, dependency parsing #OTHEREFR, among others.", "predict": "Integer linear programming #OTHEREFR; #REFR."}
{"label": "Our framework proceeds by using the standard procedure of performing word alignment using GIZA++ #OTHEREFR and obtaining phrases from the word alignment using heuristics #REFR and subsequently scoring them.", "predict": "The phrase table was constructed using the grow-diag-final-and heuristic #REFR."}
{"label": "Recent years have witnessed burgeoning development of statistical machine translation research, notably phrase-based #REFR and syntax-based approaches #OTHEREFR.", "predict": "Most state of the art machine translation systems #OTHEREFR; #REFR, and syntax-based approaches #OTHEREFR."}
{"label": "Our analysis more fully explains the positive results achieved by #REFR from reranking with prosodic features and suggests that the hypothesis that inserted prosodic punctuation breaks n-gram dependencies only partially explains the negative results of #OTHEREFR.", "predict": "Our results confirm #REFR findings that prosodic information can be useful for parsing conversational speech, but also suggest that there is room for improvement."}
{"label": "We tried to incorporate the binned prosodic information described in the previous subsection in a manner that corresponds as closely as possible to the way that punctuation is represented in this corpus, because previous experiments have shown that punctuation improves parser performance #REFR.", "predict": "In order to obtain a baseline for our experiments, we trained a statistical parser on the LDC Switchboard treebank corpus, and tested it on the same corpus, following the procedure of #REFR."}
{"label": "Measures of cross-language relatedness are useful for a large number of applications, including cross-language information retrieval #OTHEREFR, cross-language annotation and resource projections to a second language #REFR.", "predict": "The task of cross-lingual relatedness has attracted a growing interest in recent years, as it has been shown to be useful for a variety of applications, such as cross-lingual information retrieval #OTHEREFR and cross-lingual information extraction #REFR."}
{"label": "We distinguish social acts from ?social events? as described in #REFR: social events correspond to types of interactions among people, whereas a social act is associated with a fine-grained social goal and reflected in the specific choices of words and orthographic or prosodic cues at the level of a turn.", "predict": "Such social acts are distinct from social events #REFR in that they are typically aimed at a specific addressee, rather than at a larger group of people or at the general public."}
{"label": "We used 600 million Japanese Web pages #OTHEREFR parsed by KNP #REFR as a corpus.", "predict": "We used a wide-coverage Japanese syntactic analyzer #REFR to extract compound sentences in our corpus."}
{"label": "While syntactical constraints have been proven to helpful in identifying good paraphrases #REFR, it is insufficient in our task because it cannot properly filter the candidates for the replacement.", "predict": "A naive approach is to extract phrase pairs from a parallel corpus, and then replace all the phrases of a sentence pair with the extracted phrase pairs #REFR."}
{"label": "Our approach can be considered a generalization of syntactic approaches to example-based machine translation #OTHEREFR; #REFR.", "predict": "This work is also related to example-based translation #OTHEREFR; #REFR."}
{"label": "A general abstract model of incremental processing based on buffers and a processor was developed by #REFR and is illustrated in Figure 2.", "predict": "The basic architecture for incremental NLG is the?buffered incremental architecture? (BIA) #REFR."}
{"label": "We also compare our method against Wang and #REFR?s Naive-Bayes Support Vector Machine (NBSVM), which has achieved state-of-the-art results (or close to it) on many datasets, and find that it performs competitively against NBSVM.", "predict": "The results are also comparable to more complex models #OTHEREFR; #REFR."}
{"label": "The proposal in this paper is grounded on the heterogeneity property of evaluation measures introduced in #REFR.", "predict": "#REFR showed that a set of measures that have a high degree of heterogeneity tend to have a high degree of reliability."}
{"label": "The first task is to answer the closest-opposite questions from the GRE test provided by #REFR4.", "predict": "To evaluate the antonymy scores produced by MRLSA, we adopt the same test set as in #REFR."}
{"label": "However, there are state-of-the-art unlexicalized parsers #REFR, to which we believe our binarization can be applied.", "predict": "For the sake of comparison, we also include the results from the CKY parser with A* search proposed by #REFR, which has been shown to be much faster than CKY parser in practice."}
{"label": "Examples of such systems include tutoring systems, intelligent assistants, and spoken translation systems #REFR.", "predict": "For example, in the ITSPOKE system #REFR, a generic please repeat clarification might result in a long user response."}
{"label": "There has been a substantial body of work on metaphor identification and interpretation #OTHEREFR; #REFR.", "predict": "A significant amount of research has been done on the automatic identification of metaphors in texts #OTHEREFR; #REFR."}
{"label": "For a fair comparison, all aligners are trained on the same training corpora described in Section 3.2. berkeley aligner #REFR applies the co-training approach for training the IBM model 1 and HMM.", "predict": "Berkeley aligner is a popular tool for word alignment based on IBM models #OTHEREFR and on a Hidden Markov Model (HMM) #REFR."}
{"label": "It is worth noting that the German parse trees #REFR tend to be broader and shallower than those for English.", "predict": "For the other language pairs we use the default values #OTHEREFR; #REFR."}
{"label": "We identify and eliminate unimportant words, somewhat similar to Q&A retrieval #REFR.", "predict": "To reduce the noise of TM, the key words or important words are often used to construct TM, because the noise words in the corpus would not be included in TM #OTHEREFR; #REFR."}
{"label": "BBN has developed a software package, the Learner, as a porting tool for non-expert users #REFR.", "predict": "One such tool is the BBN Learner, described in #REFR."}
{"label": "We proposed a variant of an online learning algorithm inspired by a batch learning algorithm of #REFR.", "predict": "We propose an online learning algorithm for SMT based on stochastic gradient descent (SGD) #OTHEREFR; #REFR."}
{"label": "#REFR derive paraphrases from monolingual data using distributional similarity metrics.", "predict": "A different approach to paraphrase extraction has been proposed by #REFR, who extract paraphrases by pivoting through distributional similarity metrics."}
{"label": "Recently, there have been many advances in SRL #OTHEREFR; #REFR.", "predict": "Most systems use supervised machine learning techniques such as SVMs #OTHEREFR; #REFR."}
{"label": "However, some recent approaches have explored ways of using annotated non-native text either by incorporating error-tagged data into the training process #OTHEREFR, or by using native language-specific error statistics #REFR.", "predict": "Some have also trained models on error-annotated non-native text #OTHEREFR; #REFR."}
{"label": "Statistical Machine Translation #OTHEREFR and prediction of twitter responses #REFR.", "predict": "Machine Translation #OTHEREFR; #REFR."}
{"label": "Researchers have paid a lot of attention to datadriven dependency parsing in recent years #REFR.", "predict": "Dependency parsing is a process of syntactically analyzing sentences and has been successfully applied to a variety of languages #OTHEREFR; #REFR."}
{"label": "The unsupervised data that we integrate has been created by automatic translations of parts of the Arabic LDC Gigaword corpus (mostly from the HYT collection) with a standard phrase-based system #REFR.", "predict": "In this paper we use the hierarchical phrase-based translation model of #REFR."}
{"label": "Although this approach can give inaccurate estimates, the counts given to the incorrect senses will disperse randomly throughout the hierarchy as noise, and by accumulating counts up the hierarchy we will tend to gather counts from the correct senses of related words #REFR.", "predict": "This approach can lead to inaccurate results, as has been noted by several authors #REFR."}
{"label": "Our projection procedure resembles unsupervised text categorization #REFR, with categories represented by term clusters that are not predefined but rather emerge from the analyzed data:", "predict": "The projection scheme we propose in this paper is a variation of the sentence similarity metric described in #REFR."}
{"label": "A similar idea is proposed by #REFR for producing high precision data for lexical acquisition.", "predict": "This method is a variant of the?conservative? method proposed by #REFR."}
{"label": "At each step of the distant supervision process, we closely follow the recent literature #OTHEREFR; #REFR.", "predict": "We start by identifying a knowledge base that contains the relation we are interested in learning (e.g.,?born in?); for example, we can use Freebase #OTHEREFR; #REFR."}
{"label": "Discourse parsing tries to identify how the units are connected with each other and thereby uncover the hierarchical structure of the text, from which multiple NLP tasks can benefit, including text summarization #OTHEREFR, sentence compression #REFR or questionanswering #OTHEREFR.", "predict": "While a considerable amount of research has been devoted to discourse segmentation #OTHEREFR; #REFR, discourse parsing remains an open challenge."}
{"label": "The existence of the ATIS database #REFR is no doubt a factor in the popularity of the travel domain among the research community for exactly this reason.", "predict": "As a result, most current alternatives to statistical language modeling are based on hand-crafted grammars, either finite-state #OTHEREFR or context-free #REFR."}
{"label": "The graphbased method views the problem as finding an optimal tree from a fully-connected directed graph #OTHEREFR; #REFR, while the transition-based method tries to find a highest-scoring transition sequence that leads to a legal dependency tree #OTHEREFR.", "predict": "One is to decompose the problem into subproblems of individual arcs #OTHEREFR; #REFR, and the other is to directly model entire trees #OTHEREFR."}
{"label": "We use a common graph-based parsing technique #REFR; the approaches described here could be used in transition-based parsing as well.", "predict": "1.1.1 Feature-based Parsers Graph-based dependency parsers are popular in the parsing community #OTHEREFR; #REFR."}
{"label": "This is a variant of the greedy one-to-one mapping scheme of #REFR.8 With a Tag Dictionary We also ran a second version of each experimental configuration, where we used a tag dictionary to restrict the possible path sequences of the HMM during both learning and inference.", "predict": "Tag Dictionary We repeated the above experiment using the?gold? tag dictionary of #REFR."}
{"label": "First, we investigate the impact of using different flavours of Covington?s algorithm #OTHEREFR for nonprojective dependency parsing on the ten different languages provided for CoNLL-X Shared Task #REFR.", "predict": "First, we test three different parsing algorithms for non-projective dependency parsing, namely the algorithms presented in #REFR, #OTHEREFR."}
{"label": "#REFR presents a detailed overview that also mentions short-comings.", "predict": "This is confirmed by experiments #OTHEREFR; #REFR."}
{"label": "#REFR chose an approach motivated by the assumption that documents containing a large number of patterns already identified as relevant to a particular IE scenario are likely to contain further relevant patterns.", "predict": "One approach to this step is that of #REFR, which is to use a ranking algorithm based on the confidence of each pattern and the relevance of each document."}
{"label": "Finally, another soft-constraint approach that can also be viewed as coming from the data-driven side, adding syntax, is taken by #REFR.", "predict": "#REFR present a transfer-based approach that incorporates linguistic constraints on both sides of the translation."}
{"label": "The artificial data set of #REFR is widely used in the literature and enables comparison of a new segmentation method with existing ones.", "predict": "We first compare our algorithm to #REFR."}
{"label": "Another WSD approach incorporating context-dependent phrasal translation lexicons is given in #REFR and has been evaluated on several translation tasks.", "predict": "In #REFR, a sense disambiguation system was used to disambiguate phrases, and it was shown that the system improved translation quality by 0.5% in BLEU."}
{"label": "Analogous techniques for tree-structured translation models involve either allowing each nonterminal to generate both terminals and other nonterminals #REFR, or, given a constraining parse tree, to ?flatten? it #OTHEREFR.", "predict": "This suggests that the approach of using long contiguous phrases #OTHEREFR; #REFR might not be the best way to improve translation accuracy."}
{"label": "In the Second International Chinese Word Segmentation Bakeoff (the second SIGHAN CWS bakeoff) #REFR, two of the highest scoring systems in the closed track competition were based on a CRF model #OTHEREFR.", "predict": "In the second SIGHAN Chinese word segmentation bakeoff #REFR, a CRF model was used by the best-performing systems #OTHEREFR."}
{"label": "The most representative methods for relation classification use supervised paradigm; such methods have been shown to be effective and yield relatively high performance #OTHEREFR; #REFR.", "predict": "Most of the existing methods can be categorized into unsupervised #OTHEREFR; #REFR and supervised approaches."}
{"label": "We avoid the construction of (Bar-Hillel 1This problem is also relevant to other areas of statistical NLP, for example NL generation #REFR.", "predict": "The approach uses Lagrangian relaxation to decompose the decoding problem into tractable subproblems, thereby avoiding exhaustive dynamic programming, and recovers exact solutions with certificates of optimality on over 97% of test examples; it has comparable speed to state-of-the-art decoders. #OTHEREFR; #REFR."}
{"label": "The MaltParser system for English described in #REFR was used as a baseline, and then optimized for this new task, focusing on feature selection.", "predict": "The system for syntactic dependencies was MaltParser #REFR."}
{"label": "There are two dominant approaches to dependency parsing: graph-based and transition-based, where graphbased parsing is understood to be slower, but often more accurate #REFR.", "predict": "Dependency parsing is a well-studied problem in natural language processing #REFR."}
{"label": "Whereas we have concentrated on determinism in this paper, one can also introduce a limited degree of nondeterminism and allow some of the most promising configurations at each input position to compete, applying techniques such as beam search #OTHEREFR, or A ? search #REFR in order to keep the running time low.", "predict": "The parser can be further improved by using heuristics as in #REFR."}
{"label": "We carried out a comprehensive evaluation of the automatically acquired verbal semantic forms against the COMLEX Resource #REFR for the 2992 active verb lemmas that both resources have in common.", "predict": "Our lexicon contains over 30,000 semantic forms, more than Comlex #REFR."}
{"label": "Figure 2: A simple lexicalized parse tree. criminative models described in #OTHEREFR, the generative model in #REFR, the lexicalized TAG extractor in #OTHEREFR.", "predict": "Figure 2: Example of a head-lexicalized parse tree cerning the Penn Treebank #OTHEREFR; #REFR."}
{"label": "More recently, we show that our SCFG-based parser can be inverted to produce a state-of-the-art NL generator, where a formal MRL is translated into an NL #REFR.", "predict": "Following this work, a number of related efforts have emerged that use statistical techniques for learning synchronous grammars for semantic parsing and NL generation #OTHEREFR; #REFR."}
{"label": "Abstracting from results for concrete test sets, #REFR try to identify statistical and linguistic properties on that the performance of similarity metrics generally depends.", "predict": "The significant variation in the distributional similarity neighbourhoods of different metrics has been recognized by #REFR."}
{"label": "We will extend the logical engine used to infer rhetorical relations--DiCE #OTHEREFRb, #REFR--to model inferences about intentional structure and its interaction with informational structure.", "predict": "This is in line with work by #REFR and Kehler #OTHEREFR."}
{"label": "Some of these techniques have been successfully applied for NLP tasks: word sense disambiguation #REFR, sentiment analysis #OTHEREFR, to name but a few.", "predict": "A number of studies have been done on graph-based semi-supervised classification techniques #OTHEREFR; #REFR."}
{"label": "To expand our lexicon of these nouns, we started with a seed set garnered from the Penn Treebank #REFR, which uses distinctive tree structures for complement-taking nouns, and a small list of linguistically prominent nouns.", "predict": "For example, #REFR includes verbs like want and believe among the complement-taking verbs."}
{"label": "#REFR use a thesaurus to aid in the construction of a sentiment lexicon for English.", "predict": "#REFR expand a dictionary-based lexicon using affixes and thesauri for English."}
{"label": "Analyses have shown that this augmented data can lead to better statistical estimation or word coverage #REFR.", "predict": "By doing so, we can alleviate the data sparseness problem and improve translation quality #REFR."}
{"label": "In several studies (e.g., #REFR it has been shown that relatively unsupervised and language-independent methods could be used to generate many thousands of sets of words whose semantics is similar in some sense.", "predict": "In our previous work #OTHEREFR; #REFR."}
{"label": "In this study we use PropBanked versions of the Wall Street Journal (WSJ) part of the Penn Treebank #REFR and part of the Brown portion of the Penn Treebank.", "predict": "For our experiments we have used the Wall Street Journal (WSJ) and the Brown corpus #REFR."}
{"label": "More recently, various researchers have used topic models for document geolocation #OTHEREFR; #REFR or other types of geographic document summarization #OTHEREFR.", "predict": "Later work has used supervised methods, including text regression #OTHEREFR and topic models #REFR."}
{"label": "#REFR implement lexicalized content models that represent global text properties on news articles and narratives using Hidden Markov Models (HMMs).", "predict": "#REFR use a Hidden Markov Model (HMM) to assess discourse coherence."}
{"label": "The merging procedure seeks to address overfitting at the level of the features themselves and remain true to the spirit of the maximum entropy approach, which seeks to represent what is unknown about the data with uniformity of the distribution, rather than by making adjustments on the model distribution itself, such as the Gaussian prior of #REFR.", "predict": "#REFR note that in some cases, infrequent features may be more useful for estimating the parameters of a model than frequent ones, and suggest that the former be given a higher weight in the estimation process."}
{"label": "Recent experiments performed by two groups of researchers at CMU have gathered ata on subjects using speech recognizers in office-like environments #REFR.", "predict": "As part of the initial evaluation of the speech understanding system for the spreadsheet task, a number of experiments were run to determine the kinds of errors that users would make when interacting with the system #REFR."}
{"label": "A source of statistics widely used in prior work is the query log #OTHEREFR; #REFR.", "predict": "Most prior work on spelling correction for search applications #OTHEREFR; #REFR) relies on statistics from query logs."}
{"label": "Details about the speech recognition system we refer to in the paper can be found in #REFR/1).", "predict": "Several algorithms have been proposed for this task #OTHEREFR; #REFR."}
{"label": "As using complementary information has been useful in, e.g., POS error detection #REFR, we explore other simple comparable properties of a dependency grammar.", "predict": "To improve this, we adapt the methods from #REFR to our framework."}
{"label": "The linguistic information within this track is encoded in a so-called VIT 2 #REFR which is a formalism following DRT.", "predict": "The semantic representation used is the VERBMOBIL Intermediate Representation (VIT) #REFR."}
{"label": "#REFR adopted a supervised learning technique to search for useful syntactic patterns as contextual clues.", "predict": "#REFR extracted aspect-evaluation relations and aspect-of relations through syntactic patterns."}
{"label": "For more expressive, linguistically-motivated syntactic MT models #REFR, the grammar complexity has grown considerably over hierarchical phrase-based models #OTHEREFR.", "predict": "On the other hand, context-sensitive chart pruning methods for MT decoding #OTHEREFR; #REFR have not received much attention."}
{"label": "Not surprisingly, some degree of disambiguation is needed to carry out effective anonymization #REFR.", "predict": "We found that deidentification methods that work well for the general public domain do not work well for clinical text #REFR."}
{"label": "A good example of work in this space is shown in #REFR, who describe a method for phrase table reduction, sometimes substantial (>90%), with no impact on the resulting BLEU scores.", "predict": "In this work, we do not focus on this aspect, but rather focus on the impact of reducing the size of the training data. #REFR present a strategy for reducing the size of the phrasal table for a trained model."}
{"label": "Factored models #REFR factor the phrase translation probabilities over additional information annotated to each word, allowing for text to be represented on multiple levels of analysis.", "predict": "Factored models #OTHEREFR; #REFR use additional linguistic features in translation."}
{"label": "Therefore, we were less concerned with improving efficiency, and more with the properties of this algorithm, which we consider a baseline method upon which more sophisticated techniques such as best-first parsing #OTHEREFR or A search #REFR may well be able to improve.", "predict": "We will also investigate more efficient, bottom-up methods for identifying the native state of proteins, similar to the work of #REFR."}
{"label": "It has been shown that accurate discourse segmentation within a sentence greatly improves the overall parsing accuracy to near human levels #REFR.", "predict": "#REFR report results for the full sentence-level discourse parsing task, which we investigate in this section."}
{"label": "Many systems use binary features i.e. the word-internal features, which indicate the presence or absence of particular property in the word. #OTHEREFR; #REFR.", "predict": "Following are the commonly used features: #OTHEREFR; #REFR etc."}
{"label": "This 5All statistical significance tests in these experiments use the computationally-intensive randomisation test described in #REFR, with p < 0.05. work has shown that tag sequences can be successfully used to restrict the set of parses produced, but generally are not discriminatory enough to distinguish a single best parse.", "predict": "The latter work, however, was not discriminative in the sense that it only considered the top parse tree, and did not include the other trees in the forest as additional features. #REFR, p. 5) notes that this is an approximation."}
{"label": "Segmentation is a useful intermediate step in such applications as subjectivity analysis #REFR, automatic summarization #OTHEREFR and others.", "predict": "However, a text segmenter can be used as a preprocessing step for a wide range of tasks, including coreference resolution #OTHEREFR, opinion topic detection #REFR, summarization #OTHEREFR."}
{"label": "#REFR dissected parsing difficulty metrics (including surprisal and entropy) to separate out the effects of syntactic and lexical difficulties, and showed that these new metrics are strong predictors of reading difficulty.", "predict": "#REFR show that surprisal is a good predictor of reading time for a probabilistic PCFG parser."}
{"label": "Sentence splitting and tokenization was carried out using the relevant modules from the BRAT package #REFR.", "predict": "The model for Finnish is trained on the Finnish National Corpus #OTHEREFR, and the English model on the English side of the same corpus #REFR."}
{"label": "AL has been successfully applied to a number of NLP tasks such as part-of-speech tagging #OTHEREFR, and named entity recognition (NER) #REFR.", "predict": "For example, #REFR showed that for a named entity recognition task, the amount of annotation effort required for achieving 85% accuracy could be reduced by a factor of 3.5 when using AL."}
{"label": "#REFR showed a slight improvement in parsing accuracy when enough fragments were added to learn enrichments beyond manual refinements.", "predict": "#REFR showed gains from combining both large fragments and lexicalized rules."}
{"label": "There is currently support for Word- Net #OTHEREFR, and UBY #REFR, which provides access to WordNet, Wikipedia, Wiktionary, GermaNet, VerbNet, FrameNet, Omega- Wiki, and various alignments between them.", "predict": "We support WordNet #OTHEREFR, GermaNet #REFR, VerbNet #OTHEREFR."}
{"label": "We follow the approach of #REFR and predict the VDR y of an image over a collection of labelled region annotations x.", "predict": "The VDR y representation of an image is learned using the approach described in #REFR."}
{"label": "Handcrafted rules #OTHEREFR; #REFR for preordering training data and system input have been explored in numerous publications.", "predict": "#REFR introduced a method for learning reordering rules based on a maximum entropy model, which can be applied to a given training corpus."}
{"label": "#REFR found several parsing-based features and part-of-speech based features to be useful.", "predict": "Syntactic features have been used in readability assessment before #REFR."}
{"label": "Among recent op performing methods are Hidden Markov Models #REFR, maximum entropy approaches #OTHEREFR.", "predict": "Among recent op performing methods are Hidden Markov Models #OTHEREFR, maximum entropy approaches #REFR, and transformation-based learning #OTHEREFR."}
{"label": "The reordering metrics require alignments which were created using the Berkeley word alignment package version 1.1 #REFR, with the posterior probability to being 0.5.", "predict": "The word alignment was generated using the Berkeley aligner #REFR."}
{"label": "FEDA is known to not improve upon a single classifier baseline for that dataset #REFR.", "predict": "For example, #REFR report an average accuracy of 83.65% for a single classifier trained on all data."}
{"label": "Many authors (among them #REFR incorporate RA into their parsing systems, yet none rely on it solely, integrating it instead with disambiguation preferences derived from word/constituent/concept", "predict": " ofThis has led to a reevaluation of the role of syntactic structure in parsing (see, for example, #REFR; Shieber, 1986)."}
{"label": "Nevertheless, we conclude that among currently available approaches, i.e., our two algorithms and the EM-based approach of #REFR, ?familiarity maximization? is the most promising approach for automatic assignments of heads in treebanks.", "predict": "Of course, this can also be done by learning from data in a supervised manner, either by training on a small number of gold-standard head annotations #REFR, or by learning the headedness rules directly from the constituency treebank #OTHEREFR."}
{"label": "Using higher order LMs to improve the accuracy of SMT is not new. #REFR built 5-gram LMs over web using distributed cluster of machines and queried them via network requests.", "predict": "#REFR presented a distributed infrastructure to train language models on up to 2 trillion tokens resulting in language models having up to 300 billion n-grams."}
{"label": "This is perhaps unsurprising, as the finer-grained distinctions in corpora seem to be based on lexical properties more than on additional context (see, e.g., #REFR.", "predict": "While frames are useful for detecting and disambiguating errors in a corpus #REFR, and for detecting category membership in human category acquisition #OTHEREFR, they do not capture the full extent of a word?s potential categories."}
{"label": "The system translates entences in the ATIS domain #REFR between English and Mandarin Chinese.", "predict": "The system was tested on the ATIS corpus #REFR, a corpus of spoken English utterances with associated parse trees."}
{"label": "We took the model of #REFR as the baseline, and extended it with online large-margin training and an N -gram language model.", "predict": "We extended the system by Zhang and Clark #REFR by using a larger lexicon, allowing for non-terminals, and using the IBM 4-gram model."}
{"label": "In order to improve QA systems? performance many research focus on different structures such as question processing #REFR, information retrieval #OTHEREFR for ranking, answer extraction, etc.", "predict": "Previous QA systems in this area include: question-answering by natural language processing #OTHEREFR, question classification by #REFR, etc."}
{"label": "For language acquisition, a natural question is whether prosody could similarly aid grammar induction from speech #REFR.", "predict": "Punctuation has also been used as a feature in supervised parsing, to identify phrase boundaries #OTHEREFR; #REFR."}
{"label": "While many works #OTHEREFR view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others #REFR view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic.", "predict": "Some researchers have focused on building lexicons of such terms #OTHEREFR; #REFR, and some have addressed the problem of automatically determining such ORPs for new terms, by using WordNet as a knowledge source #OTHEREFR."}
{"label": "Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files #REFR, we have counted the occurrences of content words which previously appear in the same discourse file.", "predict": "In order to test this hypothesis, we constructed a new corpus by manually tagging the Brown corpus #OTHEREFR using WordNet (see #REFR)."}
{"label": "One source of constraint which our model still does not explicitly capture is the first-order dependency between alignment positions, as in the HMM model #REFR and IBM models 4+.", "predict": "The baseline in Figure 2(a) is the same as in Figure 1(a), and the exact-match feature causes it to remain the same."}
{"label": "Analysis In order to distinguish antonyms from synonyms, the polarity inducing LSA (PILSA) model #REFR takes a thesaurus as input.", "predict": "To derive a vector representation of words that captures the polarity of antonymy, we follow the approach of #REFR."}
{"label": "Given a bilingual corpus, we use GIZA++ #REFR as word alignment core algorithm.", "predict": "The word alignment is carried out with GIZA++ #REFR."}
{"label": "Several researchers explored joint DS and PS information to enhance the quality of syntactic parsing #REFR.", "predict": "There are some work that use dependency features to improve constituent parsing #OTHEREFR; #REFR."}
{"label": "We compare against the original MIML-RE model using the same dataset and evaluation methodology as #REFR.", "predict": "In the experiments, we evaluate the relation extractors on the same test set as #REFR."}
{"label": "4 Here I propose what appears to me to be the most direct probabilistic generalization of lexiealized TAG; a different treatment can be found in \\[#REFR\\].", "predict": "I will first define a version of SLTAG (stochastie lexicalized TAG) which is similar to the version defined in #REFR, and then indicate how that definition can be adapted to produce a probabilistic TAG which is similar to the version proposed by #OTHEREFR."}
{"label": "It is a fundamental and often a necessary step before linguistic knowledge acquisitions, such as training a phrase translation table in phrasal machine translation (MT) system #REFR, or extracting hierarchial phrase rules or synchronized grammars in syntax-based translation framework.", "predict": "The derived word alignment matrix is then used to extract phrases #REFR, grammar rules #OTHEREFR."}
{"label": "#REFR took the approach that large number of entities will be unlinkable, as there is a probability that the relevant KB entry is unavailable.", "predict": "#REFR proposed an approach to learn NIL."}
{"label": "The field of syntactic parsing has received a great deal of attention and progress since the creation of the Penn Treebank #OTHEREFR; #REFR.", "predict": "The statistical parsing community has made great strides in recent years, and parsers such as #REFR and Collins #OTHEREFR have achieved state-of-the-art results on the Penn Treebank."}
{"label": "Greedy local search #OTHEREFR; #REFR has typically been used for decoding in shift-reduce parsers, while beam-search has recently been applied as an alternative to reduce error-propagation #OTHEREFR.", "predict": "Greedy local search and beam-search are two common approaches for searching for the best parsing path in a shift-reduce parser #REFR."}
{"label": "This representation departs from the vector space metaphor #OTHEREFR; #REFR, commonly employed in other frameworks for distributional semantics such as LSA #OTHEREFR.", "predict": "We have demonstrated that such a graph-based representation is useful for several applications, e.g. for the automatic generation of lexical resources for thesaurus-like applications #OTHEREFR, or for composition of concepts #REFR."}
{"label": "Since Japanese does not delimit words by white-space, the unit of chunking can be a character #REFR or a morpheme #OTHEREFR.", "predict": "The output of NER is usually a sequence of morphemes labeled with one of the following semantic categories: proper nouns, common nouns, verbs, adjectives, adverbs, and particles #OTHEREFR; #REFR."}
{"label": "#REFR first identified the importance of syntactic query/corpus parsing for information retrieval, but did not consider query segmentation itself.", "predict": "NC bracketing has been applied to the related problem of indexing documents #REFR."}
{"label": "One focusses on filtering the extracted hierarchical rules either by removing redundancy #OTHEREFR or by filtering rules based on certain patterns #REFR, while the other stream is concerned about alternative approaches for learning the synchronous grammar #OTHEREFR.", "predict": "One stream is to reduce the number of rules and thus the size of the phrase table #REFR."}
{"label": "Rather than using sentence length as a proxy, measures can employ tools for automatic analysis of the syntactic structure of texts (e.g., #REFR).", "predict": "A number of recent measures use syntactic analysis #OTHEREFR; #REFR."}
{"label": "Sentence compression is typically formulated as the problem of removing secondary information from a sentence while maintaining its grammaticality and semantic structure #OTHEREFR; #REFR.", "predict": "Sentence compression is a challenging task, and the previous work #OTHEREFR; #REFR has shown that it is difficult to achieve high accuracy."}
{"label": "Features We have designed rather simple features based on the common feature set #OTHEREFR; #REFR for bunsetsu-based parsers.", "predict": "We used the features proposed in #REFR."}
{"label": "Each list contained the n-best translations produced by the phrase-based system of #REFR.", "predict": "The n-best lists were generated by the phrase-based system of #REFR."}
{"label": "In the following model, summarized here from the full description given in #REFR, we consider words to be ordered pairs consisting of a surface word, W, and a word feature, F , given as < W, F >.", "predict": "In our experiments we used a linear interpolating HMM as described in #REFR."}
{"label": "However, although it is standard practice in MT evaluation to measure increases in automatic metric scores with significance tests #OTHEREFR; #REFR, this has not been the case in papers proposing new metrics.", "predict": "Despite the importance of significance testing in many other fields of research, it is often overlooked in MT evaluation #OTHEREFR; #REFR."}
{"label": "For example, it has been shown that grammatical error detection systems with high precision maximize learning effect, and that systems with high precision but lower recall are more useful in language learning than systems with high recall and lower precision #REFR.", "predict": "#REFR argue that a high precision is important for an EDC system to have a positive learning effect."}
{"label": "The correctness of fields extracted via a conditional random field extractor has been shown to correlate well to an estimate obtained by a constrained forward-backward technique #REFR.", "predict": "For example, conditional random fields were used to estimate the confidence of information extraction patterns #REFR."}
{"label": "Previous work has shown that within a given discourse #OTHEREFR, or with respect to a given collocation #REFR, a word appears in only one sense.", "predict": "#REFR demonstrated that words tend to appear in only one sense within a local context."}
{"label": "Instead researchers condition parsing decisions on many other features, such as parent phrase-marker, and, famously, the lexical-head of the phrase #OTHEREFR; #REFR (and others).", "predict": "Instead, a variety of different approaches have been proposed for adding extra conditioning information, including the use of parse history #OTHEREFR; #REFR, the use of part-of-speech information #OTHEREFR."}
{"label": "In particular, each of/#REFR/,/Kuhns 1988/, and/Rau and Jitcobs 1988/ describes ystems that characterize news reports with results that could llOt be obtained by keyword methods alone.", "predict": "Each of/Hayes et al 1988/,/#REFR/, and/Rau and Jitcobs 1988/ describes ystems that characterize news reports with results that could llOt be obtained by keyword methods alone."}
{"label": "Unlike the typical content specification modules #OTHEREFR; #REFR, our system relies on an authoring workstation environment equipped with a knowledge elicitation scenario for joint humancomputer content specification #OTHEREFR, for the details of the knowledge elicitation scenario).", "predict": "Firstly, the system operates in a mode of interactive content acquisition #OTHEREFR, #REFR, #OTHEREFR)."}
{"label": "Approaches to this problem began by taking all fragments Fall in a treebank #OTHEREFR; #REFR.", "predict": "Therefore, previous work on TSGs has been limited to the construction of hand-crafted grammars #REFR."}
{"label": "The smoothing methods proposed in the literature #OTHEREFR, and distance-weighted averaging #REFR.", "predict": "A number of smoothing techniques have been proposed, including the additive, multiplicative and discounting smoothing approaches #OTHEREFR; #REFR."}
{"label": "Such annotated resources are scarce, expensive to create and even the largest of them tend to have low coverage #REFR, motivating the need for unsupervised or semi-supervised techniques.", "predict": "Supervised semantic parsing has been shown to perform well on a variety of tasks, including question answering #OTHEREFR; #REFR, information extraction #OTHEREFR."}
{"label": "It is highly effective for learners to receive feedback on their essays from a human tutor #REFR.", "predict": "One of the most effective ways to help learners is to provide them with feedback on their errors #REFR."}
{"label": "A review of methods for word sense disambiguation is presented by Ide and colleagues #REFR.", "predict": "Many solutions have been proposed #OTHEREFR; #REFR, but none has been found to be effective in the clinical domain."}
{"label": "Many previous works show promising results with an assumption that syntactic cohesion explains almost all translation movement for some language pairs #OTHEREFR; #REFR.", "predict": "In addition, many experiments have been shown that tree-to-string model performs better than the phrase-based model in various tasks #OTHEREFR; #REFR."}
{"label": "The pyramid method #REFR, was inspired in part by work in reading comprehension that scores content using human annotation #OTHEREFR.", "predict": "An alternate approach to assess students? writing is to compare it to the best summary of a set of documents, as defined by the pyramid method #REFR."}
{"label": "Correcting POS annotation errors can be done by applying a POS tagger and altering the input POS tags #REFR.", "predict": "For POS tagging, #REFR propose an approach for correcting errors by adding ambiguity class information."}
{"label": "The Opinosis dataset #REFR consists of short user reviews in 51 different topics.", "predict": "We evaluate our approach using the OpinionSumm dataset of #REFR."}
{"label": "Future research will investigate more sophisticated methods of text-to-text similarity for prompt-based content scoring, such as those used in #REFR.", "predict": "Therefore, it is likely that these features could be easily integrated into automated assessment systems such as #REFR."}
{"label": "We pre-process the dataset with the following tools: the Charniak Parser #REFR for parsing sentences, the WordNet similarity package #OTHEREFR for creating the SYNT and the FOR feature spaces.", "predict": "The syntactic analysis of the tweets was performed by the Charniak parser #REFR."}
{"label": "False Opinion Targets: In another case, the phrase ?wonderful time? can be matched by an opinion pattern ?Adj-{mod}-Noun?, which is widely used in previous works #REFR.", "predict": "For example,?I love this [X] because [Y]? is a very common pattern #REFR."}
{"label": "#REFR investigate questions of dialectal differences and variation in regional interests in Twitter users using a collection of geotagged tweets.", "predict": "#REFR and Mei et al#OTHEREFR analyze Twitter data to understand regional differences in language usage."}
{"label": "In addition, we have thrown further doubt on the possible use of the PTB for cross-framework parser evaluation, as recently suggested by #REFR.", "predict": "This work was prompted by a conversation with Tsujii #REFR, who pointed out that small differences in parsing accuracy can be masked by the mapping from the grammar representation to the output trees."}
{"label": "The use of prosodic and coarticulatory context has improved the effectiveness of tone and pitch accent recognition in a range of languages #OTHEREFR, and CRFs #REFR).", "predict": "The role of context in prosodic classification has been extensively demonstrated #OTHEREFR; #REFR."}
{"label": "#REFR investigated system combination using automatic generation of diverse individual systems.", "predict": "#REFR explored a similar idea by using the variation in the performance of a large number of systems that were built using different combinations of machine translation tuning settings to automatically select a diverse set of systems to use for combination."}
{"label": "Therefore, the feature model focuses on each kind of head-child pair in the dependency tree, and mainly contains four categories of features #REFRa): basic uni-gram features, basic bi-gram features, in-between POS features, and surrounding POS features.", "predict": "It has been reported in #REFR that the feature set for MSTParser contains three categories: word form, word position and dependency relation."}
{"label": "Nearly all previous work on unsupervised grammar induction has focused on learning hierarchical phrase structure #OTHEREFR; #REFR or dependency structure #OTHEREFR.", "predict": "Recent work on unsupervised parsing #OTHEREFR; #REFR."}
{"label": "Another common type of projection methods map labels from resource-rich language sentences to resource-scarce ones in a parallel corpus using word alignment information #REFR.", "predict": "Another type of projection methods are based on word alignments between source and target languages #OTHEREFR; #REFR."}
{"label": "Our interpretation is more useful than past interpretations involving marginal constraints #OTHEREFR or maximum-entropy models #REFR as it can recover the exact formulation of interpolated Kneser-Ney, and actually produces superior results. #OTHEREFR has independently noted the correspondence between the hierarchical Pitman-Yor language model and interpolated Kneser-Ney, and conjectured improved performance in the hierarchical Pitman-Yor language model, which we verify here.", "predict": "This suggests that the smoothing technique of interpolated Kneser-Ney may be seen as a particular instance of Bayesian inference, a perspective also taken by #REFR."}
{"label": "PARC 700 Dependency Bank following #REFR The results are given in Table 7.", "predict": "Table 3 shows the performance of the automatic grammars for f-structure parsing of section 23 of the WSJ part of the Penn-II treebank against the DCU 1051 and the PARC 700 Dependency Bank #REFR."}
{"label": "Although statistical approaches to automatic term recognition, e.g. #OTHEREFR; #REFR, have achieved relative success over the years, the addition of suitable linguistic information has the potential to enhance results still further, particularly in the case of small corpora or very specialised omains, where statistical information may not be so accurate.", "predict": "Statistical techniques have dominated the field of terminology in the last decade, and it is only recently that hybrid approaches have begun to appear, combining statistics with linguistic information #REFR."}
{"label": "It has received significant attention in recent years due to increasing online opinion content and applications in tasks such as automatic product recommendation systems #OTHEREFR and opinions #REFRa).", "predict": "A number of methods have been proposed for this task, including supervised classification #OTHEREFR; #REFR."}
{"label": "Results of this evaluation and comparisons with our theoretical figures are further described in #REFR.", "predict": "See #REFR for the full description of the experiment."}
{"label": "Alignments were learned using two iterations of Model 1 and two iterations of the HMM alignment model #REFR.", "predict": "The text was word-aligned using GIZA++ #REFR."}
{"label": "#REFR use machine translation for multilingual sentiment analysis.", "predict": "#REFR propose a method for transferring sentiment information between two languages."}
{"label": "Here we report first quantitative results on the ATIS3 corpus #REFR.", "predict": "Finally, we have applied the push-n-pull algorithm to the ATIS corpus of phrase-structure annotated sentences #REFR."}
{"label": "For example, citation-based summarization systems #REFR and survey generation systems #OTHEREFR can benefit from citation purpose and polarity analysis to improve paper and content selection.", "predict": "For example, in previous work #REFR we have used the results of such analysis to automatically identify the main concepts in a given paper."}
{"label": "We use MXPOST tagger #OTHEREFR for POS tagging, Charniak parser #REFR for extracting syntactic relations, SVMlight1 for SVM classifier and David Blei?s version of LDA2 for LDA training and inference.", "predict": "We use the following tools: Stanford parser #REFR for syntactic features, WordNet 2.1 for single word features, and the implementation of the na??ve Bayes classifier1 and LDA2."}
{"label": "Thanks to this sort of activation flow FIG tends to select and emit an appropriate word in an appropriate form #REFR.", "predict": "This approach is different from the way that word choice is handled in the more traditional generation systems (see #REFR)."}
{"label": "The deterministic shift/reduce classifier-based dependency parsing approach #REFR has been shown to offer state-of-the-art accuracy #OTHEREFR with high efficiency due to a greedy search strategy.", "predict": "We therefore choose to use a shift/reduce parser based on #REFR."}
{"label": "This method is more similar to the one used in #REFR, with the difference that they use only 1-best input from a base MT system.", "predict": "The final scores are then computed as the geometric mean of the BLEU scores #OTHEREFR and the capitalization score #REFR."}
{"label": "#REFR used a Roget-like thesaurus, co-occurrence statistics, and a seed set of antonyms to identify the degree of antonymy between two words, and generate a list of antonymous words.", "predict": "We use the WordNet thesaurus and the method of #REFR to compute the semantic contrast between two words."}
{"label": "The English corpus contains 47613 sentences, that were POS tagged using Stepp Tagger #OTHEREFR, and use the Lemmatizer #REFR to extract and stem content words (nouns, verbs, adjectives, adverbs).", "predict": "The English corpus contains 23092 sentences that were POS tagged using the Stanford POS Tagger #REFR."}
{"label": "#REFR introduced a corpus-based approach for generating a K ?K matrix for each verb from an average of Kronecker products of the subject and object vectors from the positively labelled subset of the training data.", "predict": "It is similar to the method of #REFR."}
{"label": "Gi#REFR reports a relation discovery algorithm based on Hearst.", "predict": "#REFR has recently demonstrated that the learning of part-whole relations can be successful using a corpus of 10,000 sentences."}
{"label": "Our error analysis above also highlights our task?s difference with previous work that identify corresponding phrases between two sentences, including phrase extraction #REFR and paraphrase extraction #OTHEREFR.", "predict": "Similar to our task, the goal of phrase extraction systems is to extract pairs of phrases #REFR."}
{"label": "To address this problem, there have been several recent attempts to incorporate into distributional semantic models a component that generates vectors for unseen linguistic structures by compositional operations in the vector space #REFR.", "predict": "Several models have been proposed to address this issue #OTHEREFR; #REFR."}
{"label": "Several approaches have modified the Lesk algorithm to reduce is exponential complexity, like the one based on Simulated Annealing #REFR.", "predict": "The original Lesk algorithm #REFR, and its simplified version #OTHEREFR have been widely used for WSD in the last decades."}
{"label": "In recent years a variety of statistical models for realization ranking that take syntax into account have been proposed, including generative models #OTHEREFR; #REFR, maximum entropy models #OTHEREFR.", "predict": "Recent advances in statistical realization have been largely driven by the use of perceptron-based ranking models #OTHEREFR; #REFR."}
{"label": "We have been building the Sandglass MT system for the Japanese-Chinese, Chinese- Japanese language pairs #OTHEREFR; #REFR.", "predict": "We have implemented our paraphrasing model for the Japanese-Chinese language pair #REFR."}
{"label": "There are two kinds of methods for morphological disambiguation: onone hand, statistical methods need little effort and obtain very good results #OTHEREFR; #REFR, at least when applied to English, but when we try to apply them to Basque we encounter additional problems; on the other hand, some rule-based systems #OTHEREFR are at least as good as statistical systems and are better adapted to free-order languages and agglutinative languages.", "predict": "Two methods have been applied to Basque language: a stochastic one, the HMM tagger #REFR, and a rule-based one, the Constraint Grammar formalism #OTHEREFR."}
{"label": "Methodologies such as lexicalisation #OTHEREFR; #REFR and tree transformations #OTHEREFR, weaken the independence assumptions and have been applied successfully to parsing and shown significant improvements over simple PCFGs.", "predict": "#REFR proposed lexicalised PCFG and history-based PCFG to improve the performance of parsing for English."}
{"label": "#REFR suggested a division of countability into five major types, based on Allan #OTHEREFR?s noun countability preferences (NCPs).", "predict": "A different approach to dealing with countability has been proposed by #REFR, which we describe below."}
{"label": "In this section we introduce basic definitions related to synchronous context-free grammars and their probabilistic extension; our notation follows #REFR.", "predict": "#REFR introduces a formalism for synchronous context-free grammars, which we now present."}
{"label": "In principle, the comparison can be done via coselection of extracted sentences #OTHEREFR; #REFR, by string-based surface measures #OTHEREFR.", "predict": "In recent years, a number of different approaches to summarization evaluation have been proposed, including precision/recall measures #REFR, ROUGE #OTHEREFR."}
{"label": "An investigation propose that boundary strength according to the measure, which the boundary strength is applied to syntactic structures and the phrase structure is viewed as an immediate constituency tree exclusively, corresponds much more closely to empirical prosodic boundary strength than does syntactic boundary strength according to a standard measure #REFR.", "predict": "However, it is also a common view that the correlation is not absolute #REFR."}
{"label": "Several methods have been proposed with regard to aligning sentences #OTHEREFR; #REFR.", "predict": "For sentence alignment, many techniques such as IBM's alignment models #OTHEREFR, K-vec #REFR, and statistical alignment method #OTHEREFR have been proposed."}
{"label": "#REFR\\] propose a large scale method, but results are reported for only one sentence, and no success rate is given.", "predict": "#REFR report a success rate of 35.8% for their method on a subset of 30 words."}
{"label": "There are also automatic measures which do not require model summaries, but compare against the source text instead #OTHEREFR; #REFR.", "predict": "Alternatively, it can be done at the semantic level, as in FRESA #REFR, Pyramid #OTHEREFR."}
{"label": "At first, additional linguistic resources, such as specialized dictionaries #REFR or transliterated words #OTHEREFR, were combined with the seed dictionary to translate context vectors.", "predict": "In #OTHEREFR; #REFR, more representative context vectors are extracted by considering a larger corpus."}
{"label": "We choose to use an earlier neural network based probabilistic model of parsing #REFR, whose hidden units can be viewed as approximations to latent variables.", "predict": "In this paper, we use a probabilistic model that has a latent variable component, a neural network parsing model #REFR."}
{"label": "In #REFR we proposed a general protocol for handling annotation discrepancies when comparing parses across different dependency theories.", "predict": "#REFR present a protocol for cross-theory evaluation which allows for direct comparison of constituency and dependency parsing results."}
{"label": "For instance, measures that compute the association strength between the elements of an expression have been employed to determine its degree of compositionality #OTHEREFR (see also #REFR for an overview and a comparison of different measures).", "predict": "#REFR and Baroni and Zamparelli #OTHEREFR use distributional properties to identify idiomatic expressions."}
{"label": "In #REFR, it is proposed a matrix-vector recursive neural network model for semantic compositionality, which has the ability to learn compositional vector representations for phrases and sentences of arbitrary length.", "predict": "In #REFRa) the authors introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length."}
{"label": "This problem is a counterpart to the image description problem #OTHEREFR; #REFR, which has so far remained largely unexplored by the community.", "predict": "Recent work in text-to-image generation #REFR has made a first step towards this goal by learning to generate descriptions of the scene layout."}
{"label": "Unlabeled data has been shown to improve the accuracy of conjunctions within complex noun phrases #REFR.", "predict": "Unlabeled data has also been shown to improve lexical features for NP parsing #REFR."}
{"label": "The method has also been popular in the related task of noun clustering #REFR.", "predict": "This method has been used in NLP in many different contexts #REFR."}
{"label": "Care was taken to ensure not just that the utterances themselves, but also the speakers of the utterances were disjoint between test and training data; as pointed out in #REFRa), failure to observe these precautions can result in substantial spurious improvements in test data results.", "predict": "This corpus is the same one that was used by #REFR."}
{"label": "Previous work on transfer-based MT systems #REFR and alignment-based transfer knowledge acquisition #OTHEREFR have proven that transfer knowledge can be best represented by declarative structure mapping (transforming) rules each of which typically consists of a pair of source and target partial structures as in the middle of Figure 2.", "predict": "We have been using MDS (Merging-Dependence-Substitution) #REFR as the framework of our paraphrase representation."}
{"label": "To speed up Viterbi parsing, sophisticated search strategies have been developed which find the most probable analysis without examining the whole set of possible analyses #OTHEREFR; #REFRa).", "predict": "Several techniques have been developed to reduce the number of edges generated by a chart parser #OTHEREFR; #REFR."}
{"label": "Historically MT researchers have focused their attention on the mismatch of linear realization of syntactic arguments #OTHEREFR and word polysemy #REFR.", "predict": "Recent studies have shown that MT can benefit from a variety of natural language processing #OTHEREFR; #REFR, lexical semantics #OTHEREFR."}
{"label": "Researchers have explored error detection for manually tagged corpora in the context of pos-tagging #REFR, dependency parsing #OTHEREFR.", "predict": "The problem of error detection in annotated data has been studied in the NLP literature #REFR."}
{"label": "Although the overall parsing style of our system integrates template-based and language-based strategies \\[#REFR\\], the skimming algorithm is actually more bottom-up or language-based.", "predict": "The skimming approach also differs from the top-down approaches of #REFR, Hirst #OTHEREFR."}
{"label": "Several unsupervised POS induction systems make use of morphological features #OTHEREFR; #REFR and this approach has been empirically proved to be helpful #OTHEREFR.", "predict": "Similarly to POS induction, it has been shown that morphological segmentations of a word can be very useful for POS induction #REFR."}
{"label": "Our data sources are the German NeGra #REFR and TIGER #OTHEREFR treebanks.", "predict": "Following #REFR, we treat parentheses and quotation marks as phrasal constituents, and attach them to the phrasal node in the tree."}
{"label": "We show that by augmenting the delexicalized direct transfer system of #REFR with cross-lingual cluster features, we are able to reduce its error by up to 13% relative.", "predict": "We show that by augmenting direct-transfer systems with features derived from cross-lingual clusters, the relative error of delexicalized dependency parsers can be reduced by up to 13% #REFR."}
{"label": "Subsequent work explored ways of exploiting linguistically annotated data for trainable generation models #REFR; Marciniak and Strube, 2005; Belz, 2005, a.o.).", "predict": "The first data-driven approach that can be trained to generate grammatical surface realisations, and that does not rely on ngram statistics, was presented in #REFR."}
{"label": "The speed and cost benefits for annotation are certainly impressive #OTHEREFR; #REFR but we hope to show that some of the greatest gains are in the very nature of the phenomena that we can now study.", "predict": "Crowdsourcing has already been shown to be useful for tasks such as annotation #OTHEREFR; #REFR and data collection for NLP applications #OTHEREFR."}
{"label": "Related sentences are represented by a word graph so that summaries constitute paths in the graph #REFR.", "predict": "Related sentences are represented by a word graph so that summaries constitute paths in the graph #REFR."}
{"label": "Most of the research as focused on bilingual terminology identification, either as parallel multiwords forms #OTHEREFR), technical terminology (e.g. the Termight system #REFR or broad-coverage translation lexicons #OTHEREFR).", "predict": "The need to extract technical terms and their translations from parallel texts has been addressed in #OTHEREFR; #REFR."}
{"label": "The domaingeneral DM was mostly abstracted from the TALK system #REFR.", "predict": "The DM and BPM components have been used in a number of SDSs, including a tourist information system #REFRb), a restaurant booking system #OTHEREFRa)."}
{"label": "This is partly due to its relevance for applications ranging from information extraction #OTHEREFR, and the modeling of textual entailment relations #REFR.", "predict": "Semantic role labeling has been shown to improve the performance of many NLP tasks such as question answering #OTHEREFR; #REFR, and machine translation #OTHEREFR."}
{"label": "Bilingual word alignments are trained and combined from two sources: GIZA #REFR and maximum entropy word aligner #OTHEREFR.", "predict": "We use GIZA++ #REFR to align the corpus in both directions, then apply the symmetric word alignment refinement #OTHEREFR."}
{"label": "Thanks to specific reordering modeling components, phrase-based SMT #OTHEREFR; #REFR are generally good at handling local reordering phenomena that are not captured inside phrases.", "predict": "Phrase-based SMT #REFR is often the SMT approach of choice for this language pair."}
{"label": "These rules can be handcrafted grammar rules, such as those of #OTHEREFR or, alternatively, extracted fully automatically from treebanks #REFR.", "predict": "While the abstract linguistic encoding is typically an f-structure in the LFG framework, #OTHEREFR; #REFR."}
{"label": "Over the years, several approaches for mining translations from non-parallel corpora have emerged #OTHEREFR; #REFR, all sharing the same Firthian assumption, often called the distributionial hypothesis #OTHEREFR, which states that words with a similar meaning are likely to appear in similar contexts across languages.", "predict": "Several methods have been proposed for identifying translations of words across comparable corpora, such as #OTHEREFR; #REFR."}
{"label": "Many computational models of compositionality focus on learning vector spaces #OTHEREFR; #REFR.", "predict": "There is a large body of work that has attempted to model this property in a variety of domains, including sentiment analysis #REFR, paraphrasing #OTHEREFR."}
{"label": "This is the approach taken by #REFR, where they estimate what in our terms are projections of the raw treebank grammar from the treebank itself.", "predict": "This approach was taken by #REFR."}
{"label": "Transliteration methods typically fall into two categories: generative approaches #OTHEREFR; #REFRa), that try to identify the correct transliteration for a word in the source language given several candidates in the target language.", "predict": "Transliteration models can be categorized into two broad categories: generative and discriminative approaches #OTHEREFR; #REFR."}
{"label": "These results are astonishing considering that #REFR ignored candidates that appeared less than 10 times (because they were unreliable). nouns because their morphological behaviors were the same as those of nouns.", "predict": "These results are comparable with those of morphological analysis for Japanese #REFR."}
{"label": "Amazon Mechanical Turk is a crowdsourcing platform that has been extensively used for obtaining low-cost human annotations for various linguistic tasks over the last few years #REFR.", "predict": "Crowdsourcing via online platforms, such as Amazon Mechanical Turk #OTHEREFR; #REFR."}
{"label": "Recently, #REFR have reported experiments on learning information structure in the Prague TreeBank.", "predict": "However, #REFR report on the results of the first attempt at automatic identification of information structure in Czech."}
{"label": "#REFR employ a semi-automatic method to improve a large-scale morphosyntactic lexicon of French #OTHEREFR).", "predict": "The method of #REFR is also closely related to ours."}
{"label": "There have been a number of recent studies on probabilistic treebank parsing of German #OTHEREFR, using the Negra treebank #REFR as their underlying data source.", "predict": "In the last few years, there has been a growing interest in probabilistic parsing of German #OTHEREFR; #REFR."}
{"label": "Finally, we have also considered ULC, which is a very simple approach to metric combination based on the unnormalized arithmetic mean of metric scores, as described by Gime?nez and Ma`#REFRa).", "predict": "The ULC metric #REFRb) is a particular instance of the multi-metric approach which we have studied in this work."}
{"label": "This weight vector is learned using a simple Perceptron like algorithm similar to the one used in #REFR.", "predict": "This is a common technique used in many previous work #OTHEREFR; #REFR."}
{"label": "They are characterized by the following properties #REFRb):", "predict": "The approach of #REFR uses a decomposable model in order to provide a framework for modeling the interactions among a set of features."}
{"label": "Work on preposition errors has used a similar classification approach and mainly differs in terms of the features employed #OTHEREFR; #REFR.", "predict": "In addition, there have been attempts to develop specialized systems for specific errors, such as preposition errors #REFR and verb errors #OTHEREFR."}
{"label": "Parallel sentences were first word-aligned using a MaxEnt aligner #REFR.", "predict": "The English side of the GALE corpus were aligned with the Chinese side using a word alignment tool #REFR."}
{"label": "Identification of semantically similar situations can be improved by the use of segmentmatching algorithms as employed in Example- Based MT and translation memories #REFR.", "predict": "The tool for example retrieval in the target language #REFR is being integrated."}
{"label": "Others have exploited the automatic transfer of some already existing annotated resource in a different medium or language (such as the translingual projection of part-of-speech tags, syntactic bracketing and inflectional morphology in #REFR, requiring no direct supervision in the foreign language).", "predict": "#REFR used no training data at all, relying instead on parallel corpora and bilingual dictionaries to bootstrap a tagger."}
{"label": "Recent work has shown how paraphrases can improve question answering through query expansion #OTHEREFR, automatic evaluation of translation and summarization by modeling alternative lexicalization #REFR, and machine translation both by dealing with out of vocabulary words and phrases #OTHEREFR.", "predict": "Examples include automatic machine translation evaluation #REFR, text summarization #OTHEREFR."}
{"label": "Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems #OTHEREFR; #REFR. ", "predict": "In the context of syntactic parsing, direct transfer of dependency parsers has been shown to be effective across languages, even when no parallel data is available #REFR. "}
{"label": "For our Chinese to English translation experiments, we generated word alignments using the Berkeley Aligner #REFR with default settings.", "predict": "For the word alignment component, we used the Berkeley Aligner #REFR, trained on the same 1 million sentences used for MT training."}
{"label": "ORIG with fixed hyperparameters performs best, with the highest VM score (a clustering measure, #REFR) and a level of segmentation close to the correct one.", "predict": "DP-STEM finds the same solution as DP-CHAR with fixed hyperparameters, but this is no longer the case with inferred hyperparameters."}
{"label": "Conditional random fields #OTHEREFR are quite effective at sequence labeling tasks like shallow parsing #REFR and namedentity extraction #OTHEREFR.", "predict": "Conditional random fields #OTHEREFR, and named-entity extraction #REFR."}
{"label": "State-of-art approaches to frame-based SRL are based on Support Vector Machines, trained over linear models of syntactic features, e.g. #REFRb), or tree-kernels, e.g. #OTHEREFR.", "predict": "Current Semantic Role Labeling #OTHEREFR; #REFR."}
{"label": "This would also include more semantic information, e.g., in the form of Brown clusters or using semantic similarity between the words composing the structure calculated with latent semantic analysis #REFRb).", "predict": "We want to integrate the syntactic and semantic information in the same structured kernel, which we have shown to be beneficial in the context of the re-ranking approach #REFR."}
{"label": "Following #REFR, we use the default parameters (? = 0.1 and ?0 = 1.0) for HDP.1 For each target word, we apply HDP to induce the senses, and a distribution of senses is produced for each ?document? in the model.", "predict": "For each instance in the test dataset, the task is to grade its senses, i.e., to determine the compatibility of each sense with the contextual instance #REFR."}
{"label": "Some of these needs can be addressed by emerging technologies for temporal analysis #OTHEREFR; #REFR.", "predict": "In addition, there is a growing interest in automatically analyzing and summarizing time-oriented narratives, such as historical texts #OTHEREFR; #REFR."}
{"label": "Our work joins others in using continuous representations to express the meaning of words and phrases #REFR and how these may be combined in a language modeling context #OTHEREFR.", "predict": "Neural networks have been successfully applied to various NLP tasks including language modeling #OTHEREFR, sentence modeling #REFR, and parsing #OTHEREFR."}
{"label": "5The meaning of the word \"synchronized\" here is exactly the same as in STAG #REFR.", "predict": "5The idea of linking source and target rules has been independently proposed by #REFR and #OTHEREFR."}
{"label": "A Data-Oriented Parsing model #OTHEREFR; #REFR, 1993a) is characterized by a corpus of analyzed language utterances, together with a set of operations that combine sub-analyses from the corpus into new analyses.", "predict": "The DOP model of #REFR can be applied to corpora with any kind of syntactic annotation."}
{"label": "Transition-based dependency parsing can be modeled under this framework, where the state consists of a stack and a queue, and the set of actions can be either the arc-eager #REFR or the arc-standard #OTHEREFR transition systems.", "predict": "Transition-based dependency parsing has been extensively studied for word-level dependency parsing #OTHEREFR; #REFR."}
{"label": "Phrase-based SMT models, such as the alignment template model #REFR, improve on word-based models because phrases provide local context which leads to better lexical choice and more reliable local reordering.", "predict": "Later phrase-based statistical machine translation models #OTHEREFR; #REFR improve over the IBM models by learning word-to-phrase alignment probabilities."}
{"label": "Similar work has also been performed in the area of query expansion using training data consisting of FAQ pages #OTHEREFR or queries and clicked snippets from query logs #REFR.", "predict": "#REFR used query snippets and user queries as parallel corpora."}
{"label": "Many approaches have been devised, including the identification of domain-specific predominant senses #OTHEREFR; #REFR, the development of domain resources #OTHEREFR.", "predict": "Early work on domain WSD was based on fully-supervised approaches where a large number of manually-created domain-specific sense inventories were required #OTHEREFR; #REFR."}
{"label": "#REFR described a WSD method and an implementation based on Roget' s Thesaurus and the training material of the 10-rnillion-word Grolier' s Encyclopedia.", "predict": "#REFR proposed a method for acquiring semantic classes from Roget is Thesaurus categories."}
{"label": "Deep and accurate text analysis based on discriminative models is not yet efficient enough as a component of real-time applications, and it is inadequate to process Web-scale corpora for knowledge acquisition #OTHEREFR or semi-supervised learning #REFR.", "predict": "Various machine learning classifiers, including Support Vector Machines #OTHEREFR; #REFR, have been widely used for natural language processing (NLP) tasks, and they have achieved state-of-the-art accuracy for these tasks."}
{"label": "We have extended non-projective unlabeled dependency parsing #REFR to a very simple non-projective labeled dependency and showed that the parser performs reasonably well with small number of features and just one iteration of training.", "predict": "#REFRb) presented an algorithm for non-projective labeled dependency parsing based on the maximum spanning tree algorithm for a directed graph."}
{"label": "There has been much recent work in attempting to convert native parser output into alternative representations for evaluation purposes, e.g. #OTHEREFR; #REFR.", "predict": "We first convert the CCG derivations produced by the CCG parser into the GRs in DepBank, using the method described in #REFR."}
{"label": "Recently, #REFR has reported a word accuracy of 92.6% for Dutch, using a `lazy' training strategy on data aligned with the correct phoneme string, and a hand-crafted system that relied on a large set of rule templates and a many-to-one mapping of characters to graphemes preceding the actual g2p conversion.", "predict": "The word accuracy for Dutch, a language in which the pronunciation rules are less complex than in English, is slightly higher than the 68% reported by #REFR."}
{"label": "Previous research has shown that RST trees can play a crucial role in building natural language generation systems #OTHEREFR and text summarization systems #REFR; can be used to increase the naturalness of machine translation outputs #OTHEREFR.", "predict": "Our RST-annotated corpus is already being used for the development of an application for automatic translation of discourse structures from Japanese to English #REFR."}
{"label": "These same features also proved crucial to subsequent approaches, e.g. #REFR.", "predict": "Subsequent research has built upon these results, including the use of support vector machines #REFR, and the use of additional features #OTHEREFR."}
{"label": "For this reason, we compute an unweighted entity-constrained mention F-measure #REFR and report all contrastive experiments with this metric.", "predict": "CEAF is a coreference evaluation metric that is more comprehensive than ACE-Value #REFR."}
{"label": "After the error miner identifies afwater as a problematic word, we employ our machine learning based LA method presented in #REFR to learn new entries for this word.", "predict": "In order to automatically generate lexical entries, we employ the Lexical Acquisition #OTHEREFR; #REFR."}
{"label": "To further assure the quality of the annotation, a series of automatic tests was performed and used as the basis of a further manual round of revision.4 Annotation guidelines were initially created based on those created by our previous domain-specific effort #REFRa) and revised throughout the annotation effort to document specific decisions made during annotation.", "predict": "In order to evaluate the primary annotations, we also annotated a random 10% of the corpus with a second annotator #OTHEREFR; #REFR."}
{"label": "These User Simulations are now commonly used in statistical learning approaches to dialogue management #OTHEREFR; #REFR, but they have not been used for context-sensitive ASR before.", "predict": "Our work is inspired by the work on User Simulations #REFR, which was shown to improve dialogue systems performance by using a model of the user?s likely behavior in a given context."}
{"label": "Other work has shown that co-occurrence of words #OTHEREFR and discourse relations #REFR also predict coherence.", "predict": "Content approaches focus on local coherence and examine the overlap in content between adjacent sentences #OTHEREFR; #REFR."}
{"label": "It is a well-documented fact #REFR that subcategorisation frames (and their frequencies) vary across domains.", "predict": "One is that our corpus contains very few examples of the frames for some of the more rare verbs in the COMLEX lexicon, a problem that is likely to be more pronounced for verbs with a small number of occurrences in the source corpus #REFR."}
{"label": "In this paper we focus on recurrent neural network architectures, which have recently advanced the state of the art in language modeling #OTHEREFR; #REFR, outperforming multi-layer feed-forward based networks in both perplexity and word error rate in speech recognition #OTHEREFR.", "predict": "In addition, several recurrent neural network language models have been proposed for various applications #OTHEREFR; #REFR."}
{"label": "As our approach for incorporating unlabeled data, we basically follow the idea proposed in #REFR.", "predict": "While CRFs have been successfully applied to many NLP tasks #OTHEREFR; #REFR, we believe that our SSL model has some advantages over those in #OTHEREFR."}
{"label": "We extended the unsupervised corpus-extracted phrase approximation method of Guevara #OTHEREFR and #REFR to estimate all known state-of-the-art cDSMs, using closedform solutions or simple iterative procedures in all cases.", "predict": "In recent years, there has been widespread interest in compositional distributional semantic models (cDSMs), that derive meaning representations for phrases from their parts #REFR."}
{"label": "The paradigm of translation for monolinguals introduced by Kay in 1973 #OTHEREFR; #REFR).", "predict": "For instance, in the early 90s, the idea of a \"translation secretary\" emerged #REFR, which was a machine translation system interacting with a human user."}
{"label": "The projected trees can be used to answer linguistic questions such as word order #REFR or bootstrap parsers #OTHEREFR.", "predict": "This process has been used to create hand-crafted CFGs for over 100 languages #REFR."}
{"label": "We evaluated our system using the standard evaluation script provided by the organizers #REFR.", "predict": "The task is defined in #REFR."}
{"label": "Second, we prune the phrase-table using a statistical significance test to measure #REFR.", "predict": "In the future, we plan to experiment with the pruning strategy of #REFR, which could further decrease the number of translation candidates."}
{"label": "To this end, patternbased approaches have long been used to induce type systems #REFR.", "predict": "While unsupervised approaches have been developed to learn general types #OTHEREFR, #REFR), they are not suitable for domain-specific types."}
{"label": "They include such topics as: work with various corpus manipulation and annotation tools, use of various POS taggers and their comparison #REFR, development of morphophonological rules in PC-Kimmo #OTHEREFR.", "predict": "These may include tagging and lemmatization with tools such as Brill?s tagger #REFR and TreeTagger #OTHEREFR."}
{"label": "First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity #OTHEREFR; #REFR.", "predict": "First, as #REFR point out, accurate classification of subjective versus objective instances is a necessary step towards more accurate sentiment classification."}
{"label": "Compared to graph-based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non-local features, as exemplified by the comparison between MaltParser and MSTParser #OTHEREFR; #REFR.", "predict": "Because of the simplicity and efficiency of the decoding algorithm, transition-based parsing has been shown to be competitive with graph-based dependency parsing #REFR, and has been used for parsing in a variety of languages, including English #OTHEREFR."}
{"label": "Unbalanced corpora are common in a number of different tasks, such as emotion detection #OTHEREFR; #REFR, text classification #OTHEREFR, and so on1.", "predict": "Unbalanced corpora are very common in NLP applications, such as automatic annotation of dialogue corpora #REFR."}
{"label": "Metrics in the Rouge family allow for skip n-grams #OTHEREFRa); #REFR take paraphrasing into account; metrics such as METEOR #OTHEREFR in that word class information is used.", "predict": "This includes the use of more general n-grams #OTHEREFR, reference sentences with paraphrased versions of the source sentence #REFR, and a variety of word-level similarity measures #OTHEREFR."}
{"label": "Therefore, recent efforts #REFR have concentrated on feature design ? wherein more intelligent features may be added.", "predict": "This framework is flexible enough to incorporate many different features #REFR, including linguistic knowledge #OTHEREFR."}
{"label": "#REFR report better results than ours on Portuguese, Slovene, Spanish and Swedish, but worse on Danish.", "predict": "The best unsupervised parsing results are reported in #REFR."}
{"label": "We used three aligners in this work: GIZA++ #OTHEREFR, jointly trained HMM #REFR, and ITG #OTHEREFR.", "predict": "We used three aligners in this study: GIZA++ #OTHEREFR, and the ITG aligner #REFR."}
{"label": "#REFR propose a solution to this problem: for each token, they define additional features based on known information, taken from other occurrences of the same token in the document.", "predict": "#REFR proposed using a single classifier for each token type that incorporates features that are sensitive to the entire document."}
{"label": "Among the current similar works, Table 4 shows that our system outperforms Chen#OTHEREFR in VV compounds, and approximates the #REFR in NN compounds.", "predict": "The work most related to ours is #REFR."}
{"label": "A similar modification was used by #REFR for the study of dependency parsing models.", "predict": "We follow the approach of #REFR in treating the main verb as the head of a verb cluster."}
{"label": "In both cases, transfer is driven by the transfer module developed and implemented by #REFRa).", "predict": "Both transfer approaches are interfaced with the existing, implemented transfer component Verbmobi1 #REFR."}
{"label": "Such text data tend to be long and generate enough context for the target task #OTHEREFR; #REFR.", "predict": "Previous work on review mining can be broadly categorized into two types: opinion mining #OTHEREFR; #REFR, and attribute extraction #OTHEREFR."}
{"label": "In a related recent approach, #REFR presented preliminary results from automatically generating related work sections for a target paper by taking a hierarchical topic tree as an input; however, the requirement of a pre-conceived topic tree limits the scalability of this system.", "predict": "Another system, ReWoS, aimed to automatically generate related work sections for research papers #REFR, but was limited to a small set of papers."}
{"label": "Although it has been shown that increasing the amount of training data for SMT improves results #REFR, not all data is beneficial, and clean data is best of all.", "predict": "For example, a system trained on a corpus with millions of tokens will benefit more from a few tens of thousands of clean sentences than from millions of noisy sentences #REFR."}
{"label": "We first extracted named entities using a Twitter-tuned NER system #REFR from millions of tweets, which we collected over a one-year period spanning from January 2012 to January 2013; we used the public streaming Twitter API to download tweets.", "predict": "We followed #REFR and #OTHEREFR to create the training set."}
{"label": "Past studies of combining alternative alignments focused on minimizing alignment errors, usually by merging alternative alignments for a sentence pair into a single alignment with the fewest number of incorrect alignment links #REFR.", "predict": "First, most previous work on word alignment #OTHEREFR; #REFR."}
{"label": "#REFR presented a statistical system that automatically produces an analysis of the rhetorical structure that holds between sets of sentences or clauses at the paragraph level.", "predict": "In this case, a system like that described in #REFR is used."}
{"label": "We employ the features of noun terms, and sentiment terms in the sentiment lexicon provided by MPQA project #REFR.", "predict": "We utilize the Stanford Opinion Mining Tool #REFR to determine the sentiment polarity of the reviews and store them in the hierarchy."}
{"label": "A translation model consists of two distinct elements: an unweighted ruleset, and a parameterization #REFR.", "predict": "In this paper, we use a hierarchical phrase-based model #REFR as our example system."}
{"label": "We are inspired by multiple sequence alignment methods in computational biology #OTHEREFR and by #REFR, who described a hidden Markov model (HMM) for document content where each state corresponds to a distinct topic and generates sentences relevant to that topic according to a language model.", "predict": "We apply an unsupervised Hidden Markov Model (HMM) to this problem, which has been successfully applied to other unsupervised text modeling tasks #REFR."}
{"label": "Unlike other languages #REFR, Chinese UNK translation cannot use information from stem and inflection analysis.", "predict": "The most popular approaches for UNK translation are backoff method #REFR and pseudo-words #OTHEREFR."}
{"label": "For this paper, we consider tree-shaped hierarchies so that tree kernels, e.g. #OTHEREFR; #REFRa), can be applied.", "predict": "Among the various kernel-based techniques, we focus on the Tree Kernels #OTHEREFR; #REFR, which are based on the tree edit distance."}
{"label": "We follow the same approach as in #REFR to build our SWSD system.", "predict": "Following the supervised SWSD approach in #REFR, we classify each target word as subjective or objective."}
{"label": "The dataset is the same as in leading works #REFR.", "predict": "This setting is the same as in #REFR."}
{"label": "Part of the work using this tool was described by #REFR.", "predict": "Achilles is a CRF-based CWS system #REFR."}
{"label": "However, the performance of context vectors drastically decreases for lower frequency terms #REFR.", "predict": "On the other hand, for less frequent terms, the context vector approach has lower performance since the context of infrequent terms is less informative #REFR."}
{"label": "#REFR explored strategies for selecting better random ?restart points? in optimization.", "predict": "#REFR compared various ways of performing random restarts in MERT."}
{"label": "The Grammar Matrix customization system #REFR presents the linguist-user with a typological questionnaire which elicits information about the language to be described.", "predict": "The Grammar Matrix #REFR is a system for creating language-specific grammars that are based on a shared core grammar and a set of modules covering cross-linguistic variation."}
{"label": "The model is called Transfer- Driven Machine Translation (TDMT) #REFR (see subsection 2.1 for details).", "predict": "This model is called TDMT #REFR."}
{"label": "These modifications, however, give a system which suffers 2See, for example, the formalisms developed in #OTHEREFR, #REFR. the problem of woulderivational equivalence', also called ispurious ambiguity', i.e. allowing multiple proofs which assign the same reading for some combination, a fact which threatens processing efficiency.", "predict": "The resulting system, however, is ambiguous in a way that is reminiscent of the'spurious ambiguity' of the approach of #REFR."}
{"label": "On the other hand, #REFR proposed a resolving algorithm for Japanese exophoric ellipses of written texts, utilizing semantic and pragmatic onstraints.", "predict": "#REFR proposed an approach where a table of preferences for each constraint is prepared."}
{"label": "Cutting introduced grouping of words into equiva.lence classes based on the set of possible tags to reduce the number of the parameters #REFR .", "predict": "Several methods have been proposed to cope with the data sparseness problem #REFR."}
{"label": "#REFR proposed several approaches for cross lingual subjectivity analysis by directly applying the translations of opinion corpus in source language to train the opinion classifier on target language.", "predict": "#REFR translated the annotated English reviews into Spanish and Romanian, and combined the original and translated reviews to train the opinion classifiers for each language."}
{"label": "#REFR evaluate various similarity measures based on 1000 frequent and 1000 infrequent target terms.", "predict": "#REFR create a gold standard thesaurus by manually extracting hyponyms from WordNet for 200 words."}
{"label": "This was the setting obtaining the best results in a word similarity dataset as reported by #REFRb).", "predict": "For more details, see #REFR."}
{"label": "In the last 4-5 years, researchers have begun to introduce compositional operations on distributional semantic representations, for instance to combine verbs with their arguments or adjectives with nouns #OTHEREFR; #REFR1.", "predict": "Recently, several researchers have proposed various operations that can be applied to the vectors that represent words in order to model their composition #OTHEREFR; #REFR."}
{"label": "MERT is the standard technique for obtaining a machine translation model fit to a specific evaluation metric #REFR.", "predict": "Many translation systems are trained using Minimum Error Rate Training (MERT) #REFR."}
{"label": "Pseudo-word evaluations are currently used to evaluate a variety of language modeling tasks #OTHEREFR; #REFR.", "predict": "Previous research has used pseudowords to evaluate selectional preferences #OTHEREFR; #REFR."}
{"label": "Statistical machine learning methods such as hidden Markov models #OTHEREFR; #REFR have become popular approaches to address the text extraction problem.", "predict": "Machine learning approaches for IE, such as the use of hidden Markov models #OTHEREFR; #REFR, are more general and have been applied successfully to a variety of tasks."}
{"label": "The advantage of using POS tags rather than words is that their probabilities can be estimated much more accurately and, consequently, more accurate prediction of wordreading time is possible #OTHEREFR; #REFR.", "predict": "The models were the same as those used in #REFR."}
{"label": "The second line of research uses comparable or bilingual corpora as the ?pivot? that binds paraphrases together #OTHEREFR; #REFR.", "predict": "Another approach to paraphrase generation has been to use some form of bilingual resource, such as a parallel corpus #OTHEREFR; #REFR."}
{"label": "These rules can be designed manually #OTHEREFR; #REFR.", "predict": "Rewrite rules have been proposed for both syntactic and lexical reordering #REFR."}
{"label": "#REFR adapt the technique of supertagging #OTHEREFR to CCG, using a standard maximum entropy tagger to assign small sets of supertags to each word.", "predict": "This is typically done by a separate component, the supertagger, and it is a key component of our CCG parser #REFR."}
{"label": "It also exploits the classification given by the COMLEX lexicon #REFR in order to calculate the deep-subject of infinitive verbs.", "predict": "The morpho-syntactic normalizer uses also the syntactic lexicon Comlex #REFR."}
{"label": "Recently, studies have explored dialog act tagging in written interactions such as emails #OTHEREFR; #REFRb), instant messaging #OTHEREFR.", "predict": "More recently, research has focused on dialog acts in written interactions #OTHEREFR; #REFR."}
{"label": "A number of relation extraction kernels have been proposed, including dependency tree kernels #OTHEREFR; #REFR.", "predict": "They have been successfully applied to relation extraction #OTHEREFR; #REFR."}
{"label": "For one, it allows a tight correspondence between syntax and semantics by letting constituent structure express argument structure #REFR.", "predict": "In particular, discontinuity is required to represent non-configurational languages such as German #REFR, which do not use empty categories for the encoding of discontinuity."}
{"label": "Recently, there have been two promising research directions for improving SMT and its evaluation: #OTHEREFR, and (b) by going beyond the sentence-level, e.g., translating at the document level #REFR.", "predict": "Recently, researchers have been exploring ways to make the translation decision at the document-level #OTHEREFR; #REFR."}
{"label": "The k?means algorithm is used for clustering the contexts, where the number of clusters is automatically discovered using the Adapted Gap Statistic #REFR.", "predict": "The contexts are then clustered using k?means #OTHEREFR; #REFR."}
{"label": "One type of approach uses information extraction techniques such as pattern matching that use strong predictions on the content and attempt to fill templates derived from a model of the domain (e.g. #REFR), thus not giving too much importance to syntactic structure.", "predict": "The approach described in #REFR and #OTHEREFR does not perform any surface analysis of the text."}
{"label": "The mapping from a word alignment to the set of licensed phrase pairs pi(a) is based on the standard rule extraction procedures used in most modern statistical systems #REFR, but extended to handle possible links #OTHEREFR.", "predict": "We follow #REFR and align using a?many-to-many? model with a d-gram projection."}
{"label": "Word alignment and tokenization can also be optimized by maximizing the likelihood of bilingual corpus #REFR.", "predict": "On the other hand, the training of word alignment can be improved by jointly optimizing the word alignment and tokenization #REFR."}
{"label": "It is also interesting to note that the best result on the validation set for estimation 4We measured significance of all the experiments in this paper with the randomized significance test #REFR. of the loss with data-defined kernels (12) and (13) was achieved when the parameter A is close to the inverse of the first component of the learned decision vector, which confirms the motivation for these kernels.", "predict": "To confirm the statistical significance of the results, we use the method proposed in #REFR."}
{"label": "The binarization method used by #REFR can cover many non-constituent rules also, but not all of them.", "predict": "However, these methods are still limited and #REFR showed that the rule coverage was only 43% for a state-of-the-art hierarchical SMT system."}
{"label": "In contrast, approaches to WSD attempt o take advantage of many different sources of information #OTHEREFR); it seems possible to obtain benefit from sources ranging from local collocational clues #REFR to membership in semantically or topically related word classes #OTHEREFR; and disambignation seems highly lexically sensitive, in effect requiring specialized isamhignators for each polysemous word.", "predict": "The most commonly used sense inventory is the #REFR sense inventory, with 100 senses, and the most commonly used training and testing corpora are the Penn Treebank #OTHEREFR."}
{"label": "One option would be to leverage unannotated text #OTHEREFR; #REFR.", "predict": "For example, one can use unannotated data to bootstrap a parser #REFR, or use a corpus of word alignments #OTHEREFR."}
{"label": "Initially all sentences are pre-processed by the CoreNLP #OTHEREFR; #REFR suite of tools, a process that includes named entity recognition, normalization, part of speech tagging, lemmatization and stemming.", "predict": "Preprocessing consisted of tokenization, stemming and part-of-speech tagging with Stanford CoreNLP #REFR."}
{"label": "Our data source is the German NeGra treebank #REFR.", "predict": "We use the NeGra treebank #REFR, a German corpus of spoken language."}
{"label": "Automatic detection of such argument alternations is important to acquisition of verb lexical semantics #REFR, and moreover, may play a role in automatic processing of language for applied tasks, such as question-answering #OTHEREFR.", "predict": "This problem has been studied in previous work on argument alternation #OTHEREFR; #REFR."}
{"label": "Only for the Machine Translation task, #REFR report several results using different Arabic segmentation schemes.", "predict": "However, #REFR explore the effect of different segmentation schemes on Statistical Machine Translation (SMT)."}
{"label": "Next, other research efforts utilized the three categories into which various types of subordinate clauses are hierarchically classified based on the ?scope-embedding preference? of Japanese subordinate clauses #OTHEREFR; #REFR.", "predict": "Next, there are the studies that focused attention on subordinate clauses #OTHEREFR; #REFR."}
{"label": "This is because in citations, the discussion of the paper cited is usually mixed with the content of the paper citing it, and sometimes also with discussion about other papers cited #REFR.", "predict": "Instead, we use the citing sentences as indicators of the impact of the paper #REFR."}
{"label": "The work of #OTHEREFR; #REFR focuses on manually constructing several lexica and rules for both polar words and related content-word negators, such as ?prevent cancer?, where prevent reverses the negative polarity of cancer.", "predict": "#REFR extend the idea of lexical sentiment polarity to multi-word phrases by constructing rules that allow polarity to shift."}
{"label": "An appealing alternative to a similar approximation to the above would use loopy belief propagation to efficiently approximate the marginals #REFR.", "predict": "#REFR propose a method for approximate training that is based on loopy belief propagation #OTHEREFR."}
{"label": "Finally, a few efforts #OTHEREFR; #REFR have tried to translate sentences into formulas of first-order logic, in order to test logical entailment with a theorem prover.", "predict": "#REFR take an alternative approach, in which the text is used to build a model of the world, and then the hypothesis is matched against the model."}
{"label": "Therefore, we prepare single bilingual signs for expressing their truth conditions if at least one of the languages has lexical items \\[#REFR\\].", "predict": "Thus, the bilingual signs we introduce here are defined by pairs of equivalent monolingual signs, and their roles are to capture the \"meanings\" of monolingual signs, which are defined by truth conditions of logical forms (see also \\[#REFR\\])."}
{"label": "#REFR use shift-reduce parsing to impose ITG #OTHEREFR constraints on phrase permutation.", "predict": "#REFR apply shift-reduce parsing to inversion transduction grammar #OTHEREFR."}
{"label": "Similar tagsets are used by other studies on grammar induction and projection #REFR.", "predict": "This tagset has been used in previous work on syntactic universals #OTHEREFR; #REFR and is shown to be sufficient for our purposes."}
{"label": "A variety of features have been explored for ERD in previous research #OTHEREFR; #REFR.", "predict": "Several feature-rich approaches have been proposed for ERD #OTHEREFR; #REFR."}
{"label": "However, it is fair to compare our work against other approaches which have attempted to disambiguate all content words in a text against some standard lexical resource, such as #REFR, #OTHEREFR.", "predict": "#REFR, McRoy #OTHEREFR are the only three papers we are aware of that use LDOCE as the sense source."}
{"label": "This feature set is very close to that used in #REFR, but not identical.", "predict": "The same features are also used in #REFR."}
{"label": "The inside weight w i and the outside weight w o in the active items deserve more attention since this is the only difference compared to #REFR.", "predict": "Following #REFR, we start with a leftmost derivation of the input sentence."}
{"label": "Various recent attempts have been made to include non-local features into graph-based dependency parsing #REFR.", "predict": "In graph-based dependency parsing, the number of features used is often limited by the inference algorithm used, as more complex features can increase parsing time exponentially #OTHEREFR; #REFR."}
{"label": "This feature set is reminiscent of the featurized representation of #REFR.", "predict": "For example, the first three values of? are VOW, CONSONANT, and LIQUID, and we define N?(x) = {vowels if? = VOW, {consonants} otherwise. (In this experiment, we used the same alignment algorithm as #REFR.) This feature is a natural extension of FAITHFULNESS, and has been used in the past #OTHEREFR."}
{"label": "For example, a popular approach to reduce annotation effort is bootstrapping from seed examples #OTHEREFR; #REFR.", "predict": "For example, #REFR use seed nouns to learn event extraction patterns, and Filatova et al#OTHEREFR automatically induce extraction slots from seed queries."}
{"label": "These efforts have been met with some success in evaluations such as phrase similarity tasks #OTHEREFR; #REFR, sentiment prediction #OTHEREFR.", "predict": "These developments include, for example, the work of Grefenstette and Sadrzadeh #OTHEREFR, and #REFR."}
{"label": "Our use of an LSVM to assign credit during joint training differs substantially from previous LSVM applications, which have induced latent linguistic structures #OTHEREFR or sentence labels #REFR.", "predict": "LSVMs have been used to learn latent variables in a variety of structured prediction problems, including sequence labeling #OTHEREFR and sentence extraction #REFR."}
{"label": "The two most popular algorithms are McDonald?s MST- Parser #REFR and Nivre?s Malt- Parser #OTHEREFR.", "predict": "Graph algorithms include Maximum Spanning Tree (MST) parsers #REFR and minimum spanning tree (MST) parsers #OTHEREFR."}
{"label": "#REFR developed a method in which they first identify (by means of affixes rules) a set of positive/negative words which act as seeds, then used a Roget-like thesaurus to mark the synonymous words for each polarity type and to generalize from the seeds.", "predict": "Finally, #REFR proposed a method based on a Roget-like thesaurus and a set of affixes."}
{"label": "We follow the candidate-ranking model proposed by #REFR.", "predict": "A common approach to this problem is to train a model that assigns a score to each mention-pair #OTHEREFR; #REFR."}
{"label": "Recent randomized language models #REFR make use of Bloom filter like structures to map n-grams to their associated probabilities or counts.", "predict": "A number of recent approaches have sought to store large language models in compact space using probabilistic data structures #OTHEREFR; #REFR."}
{"label": "#REFR introduced the concept of lexical weighting to check how well words of the phrase translate to each other.", "predict": "Most phrase-based translation models #OTHEREFR; #REFR are based on the lexical translation probability of the word pair."}
{"label": "Much work has been done on automatic Arabic diacritization #OTHEREFR; #REFR.", "predict": "In the literature, the presence or absence of nunation has been shown to be an important feature for ASR #OTHEREFR; #REFR."}
{"label": "This kind of supervision is similar to the seeding in bootstrapping literature #OTHEREFR or prototype-based learning #REFR.", "predict": "This is a common paradigm in natural language processing, from part-of-speech tagging #OTHEREFR; #REFR, to information extraction #OTHEREFR."}
{"label": "In our system, the well-known forward maximum matching algorithm #REFR is implemented.", "predict": "This approach is widely used in Chinese word segmentation #REFR."}
{"label": "The wordlevel sentiment annotation is to utilize the polarity annotation of words in each sentence and summarize the overall sentiment of each sentimentbearing word to infer the overall sentiment within the text #OTHEREFR; #REFR.", "predict": "Word-level sentiment annotation is to label the sentiment of words in the document #OTHEREFR; #REFR."}
{"label": "This alignment matrix contains scores for all word correspondences in the sentence pair and can be created using GIZA++ #OTHEREFR or the Berkeley aligner #REFR.", "predict": "The word alignment is generated using the Berkeley aligner #REFR."}
{"label": "It has already been proposed for phrase-based #OTHEREFR, hierarchical #REFR, and syntax-based #OTHEREFR systems.", "predict": "In recent years, online approaches have become popular for SMT, as they allow for efficient translation of long sentences and for the use of large translation lexicons #REFR."}
{"label": "Class-based approaches #OTHEREFR and #REFR are more promising: the implied clustering also tackles the data sparseness difficulties, but mainly they produce selectional constraints hat have a direct semantic interpretation.", "predict": "On the other hand, a method to extract collocations and, consequently, to perform a semantic tagging of words in a domain specific perspective, has been proposed in #REFR."}
{"label": "In contrast, #REFR show that parser agreement is a strong indicator of parse quality, and in parser domain adaptation, Sagae and Tsujii #OTHEREFR use agreement between parsers to choose which automatically parsed target domain items to add to the training set.", "predict": "#REFR also use parser disagreement to sample training items for parser evaluation."}
{"label": "For comparison, we also include results for a setting that only uses word forms (Forms), which was the baseline for previous work on French dependency parsing #REFRb).", "predict": "The parsers were trained on the FTB training set and evaluated on the FTB test set, the EMEA development set, and the EMEA test set, as well as on the Europarl corpus #REFR."}
{"label": "In recent years discriminative probabilistic models have been successfully applied to a number of information extraction tasks in natural language processing #OTHEREFR, noun phrase chunking #REFR and information extraction from research papers #OTHEREFR.", "predict": "In recent years, discriminative models such as maximum entropy models #OTHEREFR and conditional random fields #REFR have become the state of the art for many natural language processing tasks."}
{"label": "These records are also known as field books and reference sets in literature #REFR.", "predict": "#REFR, Agichtein and Gravano #OTHEREFR use DB records to train extractors for semi-structured text."}
{"label": "That parsing model has since been extended to make unsupervised learning more feasible #OTHEREFR; #REFRb).", "predict": "Later work has tried to learn more structure by including more words in the dependencies #OTHEREFR; #REFR."}
{"label": "This is also the task addressed by other WSD research such as #OTHEREFR; #REFR.", "predict": "There have been many WSD research efforts in the past #OTHEREFR; #REFR."}
{"label": "Statistical data about these various cooccurrence r lations is employed for a variety of applications, uch as speech recognition #OTHEREFR; #REFR.", "predict": "These data are used in a variety of applications, such as speech recognition #OTHEREFR, anaphora resolution #REFR, semantic disambiguation #OTHEREFR."}
{"label": "He has achieved state-of-the art results by applying M.E. to parsing #OTHEREFR, and sentence-boundary detection #REFR.", "predict": "He has applied M.E. to the tasks of part-of-speech tagging #OTHEREFR, sentence boundary detection #REFR, and parsing #OTHEREFR."}
{"label": "Among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging #OTHEREFR, message understanding #REFR, discourse tagging #OTHEREFR.", "predict": "These machine learning systems are often compared to rule based systems which are hand crafted by linguists #OTHEREFR; #REFR."}
{"label": "Rather than relying on volunteers or gamification, NLP research into crowdsourcing translation has focused on hiring workers on the Amazon Mechanical Turk (MTurk) platform #REFR.", "predict": "Amazon?s Mechanical Turk #OTHEREFR; #REFR."}
{"label": "Other researchers #OTHEREFR; #REFR have reported performance gains in translation by allowing deviations from monotone word and phrase order.", "predict": "More recent work in #REFR describes constraints based on the IBM models and the ITG model."}
{"label": "In addition, timeline summarization techniques #OTHEREFR and some event-event ordering models #REFR also rely on the timestamps.", "predict": "Another application is timeline summaries, which aim to identify events mentioned in a text and to order these events in a timeline, and thus document timestamps can be used as an input to such a system #REFR."}
{"label": "For example, a memorization feature is a word pair composed of the head nouns of the two NPs involved in an instance #REFR.", "predict": "For example, #REFR used a feature indicating the number of non-pronoun words in a sentence, and a feature indicating the number of pronouns in a sentence."}
{"label": "Experiments have been made on the automatic acquisition of subcategorization frames since mid 1990s #OTHEREFR; #REFR.", "predict": "The corpus-based approach to SCF acquisition has been pioneered by #OTHEREFR and #REFR."}
{"label": "Fortunately, there is a growing body of work on genre-based text classification, including #OTHEREFR; #REFR.", "predict": "This is a well-studied task #OTHEREFR; #REFR."}
{"label": "This assumption, or its minor relaxations, is relatively standard in work on unsupervised semantic parsing tasks #REFR.", "predict": "It is also an assumption of many existing supervised models #OTHEREFR; #REFR."}
{"label": "Other research has introduced the notion of identifying concepts in the input text #REFR, using a set cover algorithm to attempt to include as many concepts as possible.", "predict": "The redundancy problem is also related to the work on?document summarization? #OTHEREFR; #REFR."}
{"label": "Early work on automatically inducing semantic relations between words, starting with #REFR, uses textual patterns.", "predict": "The idea of exploiting patterns in the text to induce semantic relations was first explored by #REFR."}
{"label": "Experiments in both #OTHEREFR and #REFR find no conclusive winner among early fusion, additive late fusion, and multiplicative late fusion.", "predict": "#REFR use a similar technique for detection of disfluencies in spontaneous speech."}
{"label": "First, as in #REFR, we stipulate that some attributes of entities are more important than others, and that some words more naturally describe those attributes.", "predict": "First, we augment SPUD is lexical entries to include the basic-level terms #OTHEREFR, referring expressions #REFR, and idioms #OTHEREFR."}
{"label": "Active learning has been shown, for a number of different NLP tasks, to reduce the number of manually annotated instances needed for obtaining a consistent classifier performance #OTHEREFR; #REFR.", "predict": "Active learning has been applied to several natural language processing tasks, such as named entity recognition #OTHEREFR; #REFR, and syntactic parsing #OTHEREFR."}
{"label": "Therefore, SVMs have shown good performance for text categorization #OTHEREFR, chunking #REFR, and dependency structure analysis #OTHEREFR.", "predict": "Moreover, SVMs can be used for feature selection #OTHEREFR; #REFR."}
{"label": "First, we briefly introduce our method for constructing NCFs from raw corpora proposed in #REFR.", "predict": "We have already proposed a method for constructing nominal case frames #OTHEREFR; #REFR."}
{"label": "Traditionally, broad coverage has always been considered to be a desirable property of a grammar: the more linguistic phenomena are treated properly by the grammar, the better results can be expected when applying it to unrestricted text #OTHEREFR; #REFR).", "predict": "For many years, the goal of broad-coverage grammar development was often considered to be a rather straightforward one: simply cover as many phenomena as possible #REFR."}
{"label": "Common combination methods include the union or intersection of directional alignments, as well as heuristic interpolations between the union and intersection like grow-diag-final #REFR.", "predict": "The most popular combination heuristic, grow-diag-final #REFR, performs an element-wise majority vote between the two models, with the exception of ambiguous words that are not assigned to a consensus alignment."}
{"label": "Following #REFR, we use an n-best list of 10000 sentences but we do not initially tune the negation feature using MERT or interpolate it with other features.", "predict": "This re-ranking approach is similar to that of #REFR in that it does not change the original n-best list."}
{"label": "WASP #REFR is a model motivated by statistical synchronous parsing-based machine translation #OTHEREFR.", "predict": "The early work on semantic parsing focused on mapping natural language sentences into logical forms #OTHEREFR; #REFR."}
{"label": "The resource presented in #REFR uses a similar binomial annotation for single words; another interesting resource is WordNetAffect #OTHEREFR but it labels words senses and it cannot be used for the prior polarity validation task.", "predict": "#REFR, using the General Inquirer, manually assigned polarity scores to phrases in the MPQA corpus."}
{"label": "Previous approaches #OTHEREFR; #REFR have performed this task by modifying the type vector for T to the context s and then comparing the resulting vector T ? to the type vector of a paraphrase candidate P .", "predict": "In previous work, the meaning of a target T has been represented by all its occurrences P = act(T ) #OTHEREFR; #REFR."}
{"label": "The method #OTHEREFR aims to detect omission-type and replacement-type errors and transformation-based leaning is employed in #REFR to learn rules to detect errors for speech recognition outputs.", "predict": "Supervised learning methods have been widely used for this task #OTHEREFR; #REFR."}
{"label": "In recent years, conditional random fields #OTHEREFR and information extraction from research papers #REFR.", "predict": "Conditional Random Fields #OTHEREFR; #REFR."}
{"label": "This is a significant improvement with respect to previous results achieved by the pure distributional model reported in #REFR.", "predict": "This outcome is in line with the results achieved in #REFRb) where, on the same task, a SVM classifier achieved the best performance with a kernel-based combination of WordNet and LSA."}
{"label": "As a consequence, finding the highest scoring parse tree is a provably hard combinatorial inference problem #REFR.", "predict": "However, the computational complexity of parsing with rich features can be quite high: second-order parsing #REFR is NP-hard; higher-order parsing is #OTHEREFR."}