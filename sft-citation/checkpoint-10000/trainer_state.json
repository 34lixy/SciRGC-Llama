{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0378019355006096,
  "eval_steps": 500,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 3.041226387023926,
      "learning_rate": 9.999929382309924e-05,
      "loss": 2.5465,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.674086809158325,
      "learning_rate": 9.999711141459145e-05,
      "loss": 2.1191,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.8474769592285156,
      "learning_rate": 9.99934524815875e-05,
      "loss": 2.0855,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.0105414390563965,
      "learning_rate": 9.99883171321437e-05,
      "loss": 2.0123,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.292330026626587,
      "learning_rate": 9.998185221640655e-05,
      "loss": 2.0572,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.506629467010498,
      "learning_rate": 9.997379405184992e-05,
      "loss": 1.9896,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.989844560623169,
      "learning_rate": 9.996426005141005e-05,
      "loss": 1.9839,
      "step": 350
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.5442001819610596,
      "learning_rate": 9.99532504966469e-05,
      "loss": 2.0107,
      "step": 400
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.793586492538452,
      "learning_rate": 9.994076571269682e-05,
      "loss": 1.9635,
      "step": 450
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.323528528213501,
      "learning_rate": 9.99268060682629e-05,
      "loss": 1.9597,
      "step": 500
    },
    {
      "epoch": 0.05,
      "eval_loss": 1.9663991928100586,
      "eval_runtime": 375.5607,
      "eval_samples_per_second": 22.809,
      "eval_steps_per_second": 22.809,
      "step": 500
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.273982048034668,
      "learning_rate": 9.991137197560406e-05,
      "loss": 1.9819,
      "step": 550
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.8097622394561768,
      "learning_rate": 9.989446389052299e-05,
      "loss": 1.9666,
      "step": 600
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.4726715087890625,
      "learning_rate": 9.987608231235256e-05,
      "loss": 1.9637,
      "step": 650
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.162405014038086,
      "learning_rate": 9.985622778394114e-05,
      "loss": 1.9999,
      "step": 700
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.7328805923461914,
      "learning_rate": 9.983490089163654e-05,
      "loss": 1.8681,
      "step": 750
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.1509013175964355,
      "learning_rate": 9.981210226526876e-05,
      "loss": 1.9285,
      "step": 800
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.996627926826477,
      "learning_rate": 9.978783257813127e-05,
      "loss": 1.9105,
      "step": 850
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.316115140914917,
      "learning_rate": 9.976209254696125e-05,
      "loss": 1.9187,
      "step": 900
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.725964307785034,
      "learning_rate": 9.973488293191832e-05,
      "loss": 1.8957,
      "step": 950
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1306512355804443,
      "learning_rate": 9.97062045365622e-05,
      "loss": 1.9169,
      "step": 1000
    },
    {
      "epoch": 0.1,
      "eval_loss": 1.9241818189620972,
      "eval_runtime": 376.0516,
      "eval_samples_per_second": 22.779,
      "eval_steps_per_second": 22.779,
      "step": 1000
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.1098837852478027,
      "learning_rate": 9.967605820782888e-05,
      "loss": 1.9283,
      "step": 1050
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1934382915496826,
      "learning_rate": 9.964444483600562e-05,
      "loss": 1.9274,
      "step": 1100
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.7429251670837402,
      "learning_rate": 9.961136535470475e-05,
      "loss": 1.94,
      "step": 1150
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.3441271781921387,
      "learning_rate": 9.957682074083597e-05,
      "loss": 1.9194,
      "step": 1200
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9910212755203247,
      "learning_rate": 9.954081201457759e-05,
      "loss": 1.8845,
      "step": 1250
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.339864730834961,
      "learning_rate": 9.950334023934638e-05,
      "loss": 1.9312,
      "step": 1300
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8350248336791992,
      "learning_rate": 9.946440652176617e-05,
      "loss": 1.9396,
      "step": 1350
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.124239206314087,
      "learning_rate": 9.942401201163511e-05,
      "loss": 1.9011,
      "step": 1400
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.524446487426758,
      "learning_rate": 9.938215790189183e-05,
      "loss": 1.8853,
      "step": 1450
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.871575117111206,
      "learning_rate": 9.933884542858007e-05,
      "loss": 1.8869,
      "step": 1500
    },
    {
      "epoch": 0.16,
      "eval_loss": 1.9027903079986572,
      "eval_runtime": 375.9877,
      "eval_samples_per_second": 22.783,
      "eval_steps_per_second": 22.783,
      "step": 1500
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.290898084640503,
      "learning_rate": 9.929407587081229e-05,
      "loss": 1.9036,
      "step": 1550
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1035027503967285,
      "learning_rate": 9.924785055073186e-05,
      "loss": 1.9478,
      "step": 1600
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.8745149374008179,
      "learning_rate": 9.920017083347398e-05,
      "loss": 1.8969,
      "step": 1650
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.2044575214385986,
      "learning_rate": 9.915103812712541e-05,
      "loss": 1.905,
      "step": 1700
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9150646924972534,
      "learning_rate": 9.91004538826829e-05,
      "loss": 1.8837,
      "step": 1750
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.1617910861968994,
      "learning_rate": 9.904841959401022e-05,
      "loss": 1.8801,
      "step": 1800
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7638226747512817,
      "learning_rate": 9.899493679779421e-05,
      "loss": 1.8516,
      "step": 1850
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.4135706424713135,
      "learning_rate": 9.894000707349931e-05,
      "loss": 1.853,
      "step": 1900
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.858096957206726,
      "learning_rate": 9.888363204332087e-05,
      "loss": 1.8777,
      "step": 1950
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.6643253564834595,
      "learning_rate": 9.882581337213736e-05,
      "loss": 1.8874,
      "step": 2000
    },
    {
      "epoch": 0.21,
      "eval_loss": 1.8911160230636597,
      "eval_runtime": 719.9213,
      "eval_samples_per_second": 11.899,
      "eval_steps_per_second": 11.899,
      "step": 2000
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.237065553665161,
      "learning_rate": 9.87665527674611e-05,
      "loss": 1.8522,
      "step": 2050
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.8952043056488037,
      "learning_rate": 9.87058519793879e-05,
      "loss": 1.9402,
      "step": 2100
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.222834587097168,
      "learning_rate": 9.864371280054532e-05,
      "loss": 1.8859,
      "step": 2150
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.865684986114502,
      "learning_rate": 9.858013706603977e-05,
      "loss": 1.8453,
      "step": 2200
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.870250940322876,
      "learning_rate": 9.851512665340233e-05,
      "loss": 1.8863,
      "step": 2250
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1408908367156982,
      "learning_rate": 9.844868348253323e-05,
      "loss": 1.8272,
      "step": 2300
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0578551292419434,
      "learning_rate": 9.83808095156452e-05,
      "loss": 1.8457,
      "step": 2350
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.356229305267334,
      "learning_rate": 9.831150675720558e-05,
      "loss": 1.8723,
      "step": 2400
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.6897833347320557,
      "learning_rate": 9.824077725387698e-05,
      "loss": 1.863,
      "step": 2450
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.255444049835205,
      "learning_rate": 9.816862309445698e-05,
      "loss": 1.8707,
      "step": 2500
    },
    {
      "epoch": 0.26,
      "eval_loss": 1.8790775537490845,
      "eval_runtime": 481.0971,
      "eval_samples_per_second": 17.805,
      "eval_steps_per_second": 17.805,
      "step": 2500
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9429348707199097,
      "learning_rate": 9.809504640981637e-05,
      "loss": 1.842,
      "step": 2550
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.6812801361083984,
      "learning_rate": 9.80200493728362e-05,
      "loss": 1.9016,
      "step": 2600
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8744021654129028,
      "learning_rate": 9.79436341983437e-05,
      "loss": 1.8789,
      "step": 2650
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8612284660339355,
      "learning_rate": 9.786580314304674e-05,
      "loss": 1.8373,
      "step": 2700
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.206480026245117,
      "learning_rate": 9.778655850546734e-05,
      "loss": 1.887,
      "step": 2750
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.0365707874298096,
      "learning_rate": 9.770590262587366e-05,
      "loss": 1.8939,
      "step": 2800
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2372031211853027,
      "learning_rate": 9.762383788621096e-05,
      "loss": 1.872,
      "step": 2850
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9479032754898071,
      "learning_rate": 9.75403667100312e-05,
      "loss": 1.8533,
      "step": 2900
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.7792490720748901,
      "learning_rate": 9.74572028081497e-05,
      "loss": 1.8589,
      "step": 2950
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.921440839767456,
      "learning_rate": 9.737095420012523e-05,
      "loss": 1.9158,
      "step": 3000
    },
    {
      "epoch": 0.31,
      "eval_loss": 1.8715673685073853,
      "eval_runtime": 375.4749,
      "eval_samples_per_second": 22.814,
      "eval_steps_per_second": 22.814,
      "step": 3000
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.6785821914672852,
      "learning_rate": 9.72833066237943e-05,
      "loss": 1.9039,
      "step": 3050
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3089447021484375,
      "learning_rate": 9.719426266758234e-05,
      "loss": 1.8426,
      "step": 3100
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.362429141998291,
      "learning_rate": 9.710382496115289e-05,
      "loss": 1.8681,
      "step": 3150
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.340125560760498,
      "learning_rate": 9.701199617533003e-05,
      "loss": 1.8477,
      "step": 3200
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9372591972351074,
      "learning_rate": 9.691877902201951e-05,
      "loss": 1.822,
      "step": 3250
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9831334352493286,
      "learning_rate": 9.682417625412853e-05,
      "loss": 1.8632,
      "step": 3300
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9834494590759277,
      "learning_rate": 9.67281906654846e-05,
      "loss": 1.8539,
      "step": 3350
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.057408571243286,
      "learning_rate": 9.663082509075292e-05,
      "loss": 1.8018,
      "step": 3400
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3535547256469727,
      "learning_rate": 9.653208240535274e-05,
      "loss": 1.8423,
      "step": 3450
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.447279691696167,
      "learning_rate": 9.643196552537243e-05,
      "loss": 1.8741,
      "step": 3500
    },
    {
      "epoch": 0.36,
      "eval_loss": 1.8642303943634033,
      "eval_runtime": 771.8283,
      "eval_samples_per_second": 11.098,
      "eval_steps_per_second": 11.098,
      "step": 3500
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.781166911125183,
      "learning_rate": 9.633047740748329e-05,
      "loss": 1.8559,
      "step": 3550
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.005648374557495,
      "learning_rate": 9.622762104885232e-05,
      "loss": 1.8622,
      "step": 3600
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8431572914123535,
      "learning_rate": 9.612339948705367e-05,
      "loss": 1.8091,
      "step": 3650
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0069828033447266,
      "learning_rate": 9.601781579997893e-05,
      "loss": 1.8192,
      "step": 3700
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8699098825454712,
      "learning_rate": 9.591087310574627e-05,
      "loss": 1.8461,
      "step": 3750
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8264840841293335,
      "learning_rate": 9.580257456260825e-05,
      "loss": 1.8144,
      "step": 3800
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.202988386154175,
      "learning_rate": 9.569292336885874e-05,
      "loss": 1.8018,
      "step": 3850
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7464942932128906,
      "learning_rate": 9.558192276273826e-05,
      "loss": 1.8655,
      "step": 3900
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.728430986404419,
      "learning_rate": 9.546957602233846e-05,
      "loss": 1.8652,
      "step": 3950
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.687973141670227,
      "learning_rate": 9.535588646550531e-05,
      "loss": 1.8468,
      "step": 4000
    },
    {
      "epoch": 0.42,
      "eval_loss": 1.8575360774993896,
      "eval_runtime": 761.8518,
      "eval_samples_per_second": 11.244,
      "eval_steps_per_second": 11.244,
      "step": 4000
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1361255645751953,
      "learning_rate": 9.524085744974112e-05,
      "loss": 1.8211,
      "step": 4050
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5725908279418945,
      "learning_rate": 9.51244923721053e-05,
      "loss": 1.8847,
      "step": 4100
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6862796545028687,
      "learning_rate": 9.500679466911414e-05,
      "loss": 1.8446,
      "step": 4150
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3152294158935547,
      "learning_rate": 9.488776781663929e-05,
      "loss": 1.8724,
      "step": 4200
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5136690139770508,
      "learning_rate": 9.476741532980509e-05,
      "loss": 1.826,
      "step": 4250
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9834089279174805,
      "learning_rate": 9.464574076288479e-05,
      "loss": 1.8698,
      "step": 4300
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7330917119979858,
      "learning_rate": 9.452274770919552e-05,
      "loss": 1.8332,
      "step": 4350
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.080932378768921,
      "learning_rate": 9.439843980099228e-05,
      "loss": 1.8239,
      "step": 4400
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.5447685718536377,
      "learning_rate": 9.427282070936059e-05,
      "loss": 1.823,
      "step": 4450
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7010380029678345,
      "learning_rate": 9.414589414410807e-05,
      "loss": 1.8279,
      "step": 4500
    },
    {
      "epoch": 0.47,
      "eval_loss": 1.8509670495986938,
      "eval_runtime": 765.6978,
      "eval_samples_per_second": 11.187,
      "eval_steps_per_second": 11.187,
      "step": 4500
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7527071237564087,
      "learning_rate": 9.401766385365494e-05,
      "loss": 1.9029,
      "step": 4550
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.161766290664673,
      "learning_rate": 9.388813362492328e-05,
      "loss": 1.8655,
      "step": 4600
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6551998853683472,
      "learning_rate": 9.37573072832252e-05,
      "loss": 1.8794,
      "step": 4650
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1367743015289307,
      "learning_rate": 9.362518869214986e-05,
      "loss": 1.8394,
      "step": 4700
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.3977127075195312,
      "learning_rate": 9.349178175344939e-05,
      "loss": 1.8288,
      "step": 4750
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.182215452194214,
      "learning_rate": 9.335709040692368e-05,
      "loss": 1.8118,
      "step": 4800
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.015963315963745,
      "learning_rate": 9.322111863030398e-05,
      "loss": 1.8734,
      "step": 4850
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8315606117248535,
      "learning_rate": 9.308387043913545e-05,
      "loss": 1.792,
      "step": 4900
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0091187953948975,
      "learning_rate": 9.294534988665854e-05,
      "loss": 1.8311,
      "step": 4950
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.126819372177124,
      "learning_rate": 9.280556106368942e-05,
      "loss": 1.8166,
      "step": 5000
    },
    {
      "epoch": 0.52,
      "eval_loss": 1.8452446460723877,
      "eval_runtime": 768.59,
      "eval_samples_per_second": 11.145,
      "eval_steps_per_second": 11.145,
      "step": 5000
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6080478429794312,
      "learning_rate": 9.2664508098499e-05,
      "loss": 1.8537,
      "step": 5050
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.4967432022094727,
      "learning_rate": 9.252219515669107e-05,
      "loss": 1.8711,
      "step": 5100
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.3213655948638916,
      "learning_rate": 9.237862644107938e-05,
      "loss": 1.8601,
      "step": 5150
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0912673473358154,
      "learning_rate": 9.223380619156332e-05,
      "loss": 1.8325,
      "step": 5200
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.8364551067352295,
      "learning_rate": 9.208773868500295e-05,
      "loss": 1.8325,
      "step": 5250
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9978551864624023,
      "learning_rate": 9.194042823509248e-05,
      "loss": 1.7977,
      "step": 5300
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.897727131843567,
      "learning_rate": 9.1791879192233e-05,
      "loss": 1.8599,
      "step": 5350
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.649169683456421,
      "learning_rate": 9.164209594340398e-05,
      "loss": 1.8436,
      "step": 5400
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8539910316467285,
      "learning_rate": 9.149108291203368e-05,
      "loss": 1.8258,
      "step": 5450
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9827814102172852,
      "learning_rate": 9.133884455786854e-05,
      "loss": 1.8289,
      "step": 5500
    },
    {
      "epoch": 0.57,
      "eval_loss": 1.8421481847763062,
      "eval_runtime": 375.6252,
      "eval_samples_per_second": 22.805,
      "eval_steps_per_second": 22.805,
      "step": 5500
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.474600315093994,
      "learning_rate": 9.11853853768415e-05,
      "loss": 1.8324,
      "step": 5550
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.904646396636963,
      "learning_rate": 9.103070990093915e-05,
      "loss": 1.8445,
      "step": 5600
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7544816732406616,
      "learning_rate": 9.0874822698068e-05,
      "loss": 1.8055,
      "step": 5650
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8418610095977783,
      "learning_rate": 9.071772837191948e-05,
      "loss": 1.7925,
      "step": 5700
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.2300875186920166,
      "learning_rate": 9.0559431561834e-05,
      "loss": 1.8302,
      "step": 5750
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.322922945022583,
      "learning_rate": 9.039993694266404e-05,
      "loss": 1.8022,
      "step": 5800
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8568878173828125,
      "learning_rate": 9.023924922463591e-05,
      "loss": 1.8352,
      "step": 5850
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9579871892929077,
      "learning_rate": 9.007737315321083e-05,
      "loss": 1.7918,
      "step": 5900
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.860766887664795,
      "learning_rate": 8.991431350894467e-05,
      "loss": 1.8005,
      "step": 5950
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.6469751596450806,
      "learning_rate": 8.975007510734681e-05,
      "loss": 1.8639,
      "step": 6000
    },
    {
      "epoch": 0.62,
      "eval_loss": 1.8373663425445557,
      "eval_runtime": 376.1252,
      "eval_samples_per_second": 22.774,
      "eval_steps_per_second": 22.774,
      "step": 6000
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.5426045656204224,
      "learning_rate": 8.958466279873793e-05,
      "loss": 1.8555,
      "step": 6050
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.0970075130462646,
      "learning_rate": 8.941808146810677e-05,
      "loss": 1.8947,
      "step": 6100
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.2159323692321777,
      "learning_rate": 8.925033603496582e-05,
      "loss": 1.7807,
      "step": 6150
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.180244207382202,
      "learning_rate": 8.908143145320611e-05,
      "loss": 1.7951,
      "step": 6200
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.139477014541626,
      "learning_rate": 8.891137271095085e-05,
      "loss": 1.8159,
      "step": 6250
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9368351697921753,
      "learning_rate": 8.874016483040817e-05,
      "loss": 1.787,
      "step": 6300
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.3941173553466797,
      "learning_rate": 8.856781286772277e-05,
      "loss": 1.8014,
      "step": 6350
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.062016725540161,
      "learning_rate": 8.839432191282658e-05,
      "loss": 1.7849,
      "step": 6400
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1175906658172607,
      "learning_rate": 8.821969708928849e-05,
      "loss": 1.8178,
      "step": 6450
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.4323720932006836,
      "learning_rate": 8.804394355416305e-05,
      "loss": 1.8275,
      "step": 6500
    },
    {
      "epoch": 0.67,
      "eval_loss": 1.833238124847412,
      "eval_runtime": 375.9536,
      "eval_samples_per_second": 22.785,
      "eval_steps_per_second": 22.785,
      "step": 6500
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.4238367080688477,
      "learning_rate": 8.78670664978381e-05,
      "loss": 1.8207,
      "step": 6550
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.068248748779297,
      "learning_rate": 8.768907114388154e-05,
      "loss": 1.9067,
      "step": 6600
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7044296264648438,
      "learning_rate": 8.750996274888707e-05,
      "loss": 1.8228,
      "step": 6650
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.0524232387542725,
      "learning_rate": 8.732974660231891e-05,
      "loss": 1.8269,
      "step": 6700
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.852670669555664,
      "learning_rate": 8.714842802635565e-05,
      "loss": 1.8369,
      "step": 6750
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7880585193634033,
      "learning_rate": 8.696601237573303e-05,
      "loss": 1.8526,
      "step": 6800
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.6987783908843994,
      "learning_rate": 8.678250503758576e-05,
      "loss": 1.8374,
      "step": 6850
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.6382486820220947,
      "learning_rate": 8.659791143128857e-05,
      "loss": 1.8264,
      "step": 6900
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.466909646987915,
      "learning_rate": 8.641223700829602e-05,
      "loss": 1.7954,
      "step": 6950
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.1289660930633545,
      "learning_rate": 8.622548725198157e-05,
      "loss": 1.8866,
      "step": 7000
    },
    {
      "epoch": 0.73,
      "eval_loss": 1.8290306329727173,
      "eval_runtime": 435.2569,
      "eval_samples_per_second": 19.68,
      "eval_steps_per_second": 19.68,
      "step": 7000
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.7343124151229858,
      "learning_rate": 8.603766767747563e-05,
      "loss": 1.8218,
      "step": 7050
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8166091442108154,
      "learning_rate": 8.58487838315027e-05,
      "loss": 1.7893,
      "step": 7100
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.242954730987549,
      "learning_rate": 8.565884129221756e-05,
      "loss": 1.8058,
      "step": 7150
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7846136093139648,
      "learning_rate": 8.546784566904049e-05,
      "loss": 1.8177,
      "step": 7200
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.2284581661224365,
      "learning_rate": 8.527580260249171e-05,
      "loss": 1.8319,
      "step": 7250
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7216888666152954,
      "learning_rate": 8.508271776402467e-05,
      "loss": 1.8235,
      "step": 7300
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.243340492248535,
      "learning_rate": 8.489248939047553e-05,
      "loss": 1.8171,
      "step": 7350
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.105879783630371,
      "learning_rate": 8.469735869578634e-05,
      "loss": 1.7469,
      "step": 7400
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7112528085708618,
      "learning_rate": 8.450120331189775e-05,
      "loss": 1.8853,
      "step": 7450
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4867514371871948,
      "learning_rate": 8.430402903170904e-05,
      "loss": 1.8176,
      "step": 7500
    },
    {
      "epoch": 0.78,
      "eval_loss": 1.8262355327606201,
      "eval_runtime": 375.6193,
      "eval_samples_per_second": 22.805,
      "eval_steps_per_second": 22.805,
      "step": 7500
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2468955516815186,
      "learning_rate": 8.41058416782097e-05,
      "loss": 1.7817,
      "step": 7550
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.8202186822891235,
      "learning_rate": 8.390664710430751e-05,
      "loss": 1.7956,
      "step": 7600
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9152857065200806,
      "learning_rate": 8.37064511926557e-05,
      "loss": 1.7894,
      "step": 7650
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7994464635849,
      "learning_rate": 8.350525985547914e-05,
      "loss": 1.8223,
      "step": 7700
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.54768967628479,
      "learning_rate": 8.330307903439987e-05,
      "loss": 1.8194,
      "step": 7750
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9802173376083374,
      "learning_rate": 8.309991470026152e-05,
      "loss": 1.8109,
      "step": 7800
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2201437950134277,
      "learning_rate": 8.289577285295307e-05,
      "loss": 1.806,
      "step": 7850
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9641252756118774,
      "learning_rate": 8.269065952123154e-05,
      "loss": 1.8147,
      "step": 7900
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.3935515880584717,
      "learning_rate": 8.248458076254406e-05,
      "loss": 1.7967,
      "step": 7950
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8172551393508911,
      "learning_rate": 8.227754266284895e-05,
      "loss": 1.8061,
      "step": 8000
    },
    {
      "epoch": 0.83,
      "eval_loss": 1.8217939138412476,
      "eval_runtime": 568.0085,
      "eval_samples_per_second": 15.081,
      "eval_steps_per_second": 15.081,
      "step": 8000
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8222713470458984,
      "learning_rate": 8.207372046490299e-05,
      "loss": 1.7866,
      "step": 8050
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.5190141201019287,
      "learning_rate": 8.186480093552114e-05,
      "loss": 1.7904,
      "step": 8100
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.424774408340454,
      "learning_rate": 8.165494036859102e-05,
      "loss": 1.8428,
      "step": 8150
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.2783994674682617,
      "learning_rate": 8.144414496175602e-05,
      "loss": 1.8033,
      "step": 8200
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.136232376098633,
      "learning_rate": 8.123242094026742e-05,
      "loss": 1.8327,
      "step": 8250
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.4009754657745361,
      "learning_rate": 8.101977455680054e-05,
      "loss": 1.8949,
      "step": 8300
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7378000020980835,
      "learning_rate": 8.080621209127005e-05,
      "loss": 1.808,
      "step": 8350
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.108712911605835,
      "learning_rate": 8.059173985064459e-05,
      "loss": 1.8245,
      "step": 8400
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.2104713916778564,
      "learning_rate": 8.037636416876035e-05,
      "loss": 1.7933,
      "step": 8450
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9925682544708252,
      "learning_rate": 8.016009140613425e-05,
      "loss": 1.8166,
      "step": 8500
    },
    {
      "epoch": 0.88,
      "eval_loss": 1.8180097341537476,
      "eval_runtime": 769.3735,
      "eval_samples_per_second": 11.134,
      "eval_steps_per_second": 11.134,
      "step": 8500
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.1291942596435547,
      "learning_rate": 7.994292794977591e-05,
      "loss": 1.8481,
      "step": 8550
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0525476932525635,
      "learning_rate": 7.972488021299907e-05,
      "loss": 1.8845,
      "step": 8600
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9253541231155396,
      "learning_rate": 7.950595463523227e-05,
      "loss": 1.8262,
      "step": 8650
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5874600410461426,
      "learning_rate": 7.928615768182854e-05,
      "loss": 1.7638,
      "step": 8700
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7431576251983643,
      "learning_rate": 7.906549584387467e-05,
      "loss": 1.7749,
      "step": 8750
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7817438840866089,
      "learning_rate": 7.884397563799928e-05,
      "loss": 1.7706,
      "step": 8800
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7651270627975464,
      "learning_rate": 7.862160360618053e-05,
      "loss": 1.8079,
      "step": 8850
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9286839962005615,
      "learning_rate": 7.839838631555283e-05,
      "loss": 1.8431,
      "step": 8900
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.2816522121429443,
      "learning_rate": 7.817433035821302e-05,
      "loss": 1.8176,
      "step": 8950
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8573153018951416,
      "learning_rate": 7.79494423510255e-05,
      "loss": 1.8146,
      "step": 9000
    },
    {
      "epoch": 0.93,
      "eval_loss": 1.815437912940979,
      "eval_runtime": 774.8378,
      "eval_samples_per_second": 11.055,
      "eval_steps_per_second": 11.055,
      "step": 9000
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9485034942626953,
      "learning_rate": 7.772372893542703e-05,
      "loss": 1.8168,
      "step": 9050
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.015392303466797,
      "learning_rate": 7.749719677723044e-05,
      "loss": 1.7888,
      "step": 9100
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8484883308410645,
      "learning_rate": 7.726985256642784e-05,
      "loss": 1.8451,
      "step": 9150
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.527937173843384,
      "learning_rate": 7.704170301699302e-05,
      "loss": 1.8082,
      "step": 9200
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.7061614990234375,
      "learning_rate": 7.68127548666832e-05,
      "loss": 1.8035,
      "step": 9250
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.360776662826538,
      "learning_rate": 7.658301487684007e-05,
      "loss": 1.7782,
      "step": 9300
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.003507137298584,
      "learning_rate": 7.635248983219003e-05,
      "loss": 1.7658,
      "step": 9350
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.7896604537963867,
      "learning_rate": 7.612118654064388e-05,
      "loss": 1.831,
      "step": 9400
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7691603899002075,
      "learning_rate": 7.58891118330958e-05,
      "loss": 1.8092,
      "step": 9450
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9659950733184814,
      "learning_rate": 7.565627256322151e-05,
      "loss": 1.8108,
      "step": 9500
    },
    {
      "epoch": 0.99,
      "eval_loss": 1.8119055032730103,
      "eval_runtime": 771.1719,
      "eval_samples_per_second": 11.108,
      "eval_steps_per_second": 11.108,
      "step": 9500
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1698355674743652,
      "learning_rate": 7.542267560727605e-05,
      "loss": 1.8487,
      "step": 9550
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.2660233974456787,
      "learning_rate": 7.518832786389045e-05,
      "loss": 1.7808,
      "step": 9600
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.280083179473877,
      "learning_rate": 7.495323625386822e-05,
      "loss": 1.7834,
      "step": 9650
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.6064881086349487,
      "learning_rate": 7.47174077199809e-05,
      "loss": 1.7952,
      "step": 9700
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.1884846687316895,
      "learning_rate": 7.448084922676299e-05,
      "loss": 1.7304,
      "step": 9750
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.2477169036865234,
      "learning_rate": 7.424356776030626e-05,
      "loss": 1.7309,
      "step": 9800
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.8042830228805542,
      "learning_rate": 7.400557032805352e-05,
      "loss": 1.7428,
      "step": 9850
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.9007625579833984,
      "learning_rate": 7.376686395859158e-05,
      "loss": 1.7598,
      "step": 9900
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.7488491535186768,
      "learning_rate": 7.352745570144376e-05,
      "loss": 1.7443,
      "step": 9950
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.8013010025024414,
      "learning_rate": 7.328735262686163e-05,
      "loss": 1.8093,
      "step": 10000
    },
    {
      "epoch": 1.04,
      "eval_loss": 1.8106255531311035,
      "eval_runtime": 770.5791,
      "eval_samples_per_second": 11.116,
      "eval_steps_per_second": 11.116,
      "step": 10000
    }
  ],
  "logging_steps": 50,
  "max_steps": 28905,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "total_flos": 2.7664708343674307e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
